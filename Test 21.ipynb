{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:49:43.371051Z",
     "start_time": "2024-10-29T17:49:43.353478Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": 253
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:50:01.739234Z",
     "start_time": "2024-10-29T17:49:44.194890Z"
    }
   },
   "source": [
    "# Load the data\n",
    "nordpool = pd.read_csv('New Data/2021/Nordpool DKK.csv')\n",
    "energinet = pd.read_csv('New Data/2021/Energinet DKK.csv')\n",
    "weather_observation = pd.read_csv('New Data/2021/Weather Observation.csv')\n",
    "weather_forecast = pd.read_csv('New Data/2021/Weather Forecast.csv')\n",
    "network = pd.read_csv('New Data/2021/Network Manager 21.csv')\n",
    "\n",
    "# Filter energinet price area\n",
    "energinet = energinet[energinet['PriceArea | PriceArea | 804696'] == 'DK2']\n",
    "# Drop price area\n",
    "energinet.drop('PriceArea | PriceArea | 804696', axis=1, inplace=True)\n",
    "\n",
    "# Convert ts to datetime\n",
    "nordpool['ts'] = pd.to_datetime(nordpool['ts'])\n",
    "energinet['ts'] = pd.to_datetime(energinet['ts'])\n",
    "weather_observation['ts'] = pd.to_datetime(weather_observation['ts'])\n",
    "weather_forecast['ts'] = pd.to_datetime(weather_forecast['ts'])\n",
    "network['ts'] = pd.to_datetime(network['ts'])\n",
    "\n",
    "# Resample network_manager data to hourly intervals (average the data)\n",
    "network = network.set_index('ts')\n",
    "network = network.resample('h').mean()\n",
    "network.reset_index(inplace=True)"
   ],
   "outputs": [],
   "execution_count": 254
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:50:01.754896Z",
     "start_time": "2024-10-29T17:50:01.739234Z"
    }
   },
   "cell_type": "code",
   "source": "network.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   ts  \\\n",
       "0 2021-01-01 00:00:00   \n",
       "1 2021-01-01 01:00:00   \n",
       "2 2021-01-01 02:00:00   \n",
       "3 2021-01-01 03:00:00   \n",
       "4 2021-01-01 04:00:00   \n",
       "\n",
       "   Hasle Common 10kV Lines Voltage | has_fel_10kvskinnespend | 804133  \\\n",
       "0                                          10.505372                    \n",
       "1                                          10.499852                    \n",
       "2                                          10.440138                    \n",
       "3                                          10.423414                    \n",
       "4                                          10.401766                    \n",
       "\n",
       "   Hasle Vind Active Power | has_vin_effekt | 804123  \\\n",
       "0                                           0.310046   \n",
       "1                                           0.739963   \n",
       "2                                           0.877331   \n",
       "3                                           0.842384   \n",
       "4                                           0.469178   \n",
       "\n",
       "   Hasle Vind Current | has_vin_belastning | 804117  \n",
       "0                                         19.138536  \n",
       "1                                         42.792531  \n",
       "2                                         50.523536  \n",
       "3                                         47.936477  \n",
       "4                                         28.816449  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>Hasle Common 10kV Lines Voltage | has_fel_10kvskinnespend | 804133</th>\n",
       "      <th>Hasle Vind Active Power | has_vin_effekt | 804123</th>\n",
       "      <th>Hasle Vind Current | has_vin_belastning | 804117</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>10.505372</td>\n",
       "      <td>0.310046</td>\n",
       "      <td>19.138536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 01:00:00</td>\n",
       "      <td>10.499852</td>\n",
       "      <td>0.739963</td>\n",
       "      <td>42.792531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 02:00:00</td>\n",
       "      <td>10.440138</td>\n",
       "      <td>0.877331</td>\n",
       "      <td>50.523536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 03:00:00</td>\n",
       "      <td>10.423414</td>\n",
       "      <td>0.842384</td>\n",
       "      <td>47.936477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 04:00:00</td>\n",
       "      <td>10.401766</td>\n",
       "      <td>0.469178</td>\n",
       "      <td>28.816449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 255
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:50:01.786121Z",
     "start_time": "2024-10-29T17:50:01.754896Z"
    }
   },
   "source": [
    "# Compare length of dfs + get first & last timestamp\n",
    "def get_first_last(**dfs):\n",
    "    # Initialize\n",
    "    first_last = pd.DataFrame(index=['first', 'last', 'length', 'start_check', 'end_check'])\n",
    "    col_name='ts'\n",
    "    # Save first and last timestamp for each dataframe\n",
    "    for name, df in dfs.items():\n",
    "        first_ts = df['ts'].iloc[0]\n",
    "        last_ts = df['ts'].iloc[-1]\n",
    "        start_check = start == first_ts\n",
    "        end_check = end == last_ts\n",
    "        first_last[name] = [first_ts, last_ts, len(df), start_check, end_check]\n",
    "    return first_last\n",
    "\n",
    "# Initialize\n",
    "start = pd.to_datetime('2021-01-01 00:00:00')\n",
    "end = pd.to_datetime('2021-12-31 23:00:00')\n",
    "\n",
    "print(\"Length of a year in hours:\", 365*24)\n",
    "get_first_last(nordpool=nordpool, energinet=energinet, weather_observation=weather_observation, weather_forecast=weather_forecast, network=network)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of a year in hours: 8760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                        nordpool            energinet  weather_observation  \\\n",
       "first        2021-01-02 00:00:00  2021-01-01 00:00:00  2021-01-15 16:00:00   \n",
       "last         2021-12-31 23:00:00  2021-12-31 23:00:00  2021-12-31 23:00:00   \n",
       "length                      8735                 8759                 7936   \n",
       "start_check                False                 True                False   \n",
       "end_check                   True                 True                 True   \n",
       "\n",
       "                weather_forecast              network  \n",
       "first        2021-01-01 00:00:00  2021-01-01 00:00:00  \n",
       "last         2021-12-29 11:00:00  2021-12-31 23:00:00  \n",
       "length                      8694                 8760  \n",
       "start_check                 True                 True  \n",
       "end_check                  False                 True  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nordpool</th>\n",
       "      <th>energinet</th>\n",
       "      <th>weather_observation</th>\n",
       "      <th>weather_forecast</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2021-01-02 00:00:00</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>2021-01-15 16:00:00</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2021-12-31 23:00:00</td>\n",
       "      <td>2021-12-31 23:00:00</td>\n",
       "      <td>2021-12-31 23:00:00</td>\n",
       "      <td>2021-12-29 11:00:00</td>\n",
       "      <td>2021-12-31 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>8735</td>\n",
       "      <td>8759</td>\n",
       "      <td>7936</td>\n",
       "      <td>8694</td>\n",
       "      <td>8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_check</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_check</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 256
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:50:01.832883Z",
     "start_time": "2024-10-29T17:50:01.786121Z"
    }
   },
   "source": [
    "# Merge the dataframes on network with left join\n",
    "data = pd.merge(network, weather_forecast, on='ts', how='left')\n",
    "data = pd.merge(data, weather_observation, on='ts', how='left') \n",
    "\n",
    "# Sort the data by the timestamp column 'ts' to ensure time order\n",
    "data21 = data.sort_values(by='ts')\n",
    "\n",
    "# Save to csv\n",
    "# data21.to_csv('New Data/2021/Wind Data 21.csv', index=False)\n",
    "\n",
    "data21.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   ts  \\\n",
       "0 2021-01-01 00:00:00   \n",
       "1 2021-01-01 01:00:00   \n",
       "2 2021-01-01 02:00:00   \n",
       "3 2021-01-01 03:00:00   \n",
       "4 2021-01-01 04:00:00   \n",
       "\n",
       "   Hasle Common 10kV Lines Voltage | has_fel_10kvskinnespend | 804133  \\\n",
       "0                                          10.505372                    \n",
       "1                                          10.499852                    \n",
       "2                                          10.440138                    \n",
       "3                                          10.423414                    \n",
       "4                                          10.401766                    \n",
       "\n",
       "   Hasle Vind Active Power | has_vin_effekt | 804123  \\\n",
       "0                                           0.310046   \n",
       "1                                           0.739963   \n",
       "2                                           0.877331   \n",
       "3                                           0.842384   \n",
       "4                                           0.469178   \n",
       "\n",
       "   Hasle Vind Current | has_vin_belastning | 804117  \\\n",
       "0                                         19.138536   \n",
       "1                                         42.792531   \n",
       "2                                         50.523536   \n",
       "3                                         47.936477   \n",
       "4                                         28.816449   \n",
       "\n",
       "   Weather forecast for the max air temperature for the coming 6 hours at Bornholm | 9F7P/00/00/MET-Norway/forecast/air_temperature_max | 128206  \\\n",
       "0                                          275.52020                                                                                               \n",
       "1                                          275.50630                                                                                               \n",
       "2                                          275.13600                                                                                               \n",
       "3                                          274.88626                                                                                               \n",
       "4                                          274.93670                                                                                               \n",
       "\n",
       "   Weather forecast for wind direction at Bornholm | 9F7P/00/00/MET-Norway/forecast/wind_direction | 128270  \\\n",
       "0                                          189.13286                                                          \n",
       "1                                          191.73468                                                          \n",
       "2                                          184.39082                                                          \n",
       "3                                          178.39856                                                          \n",
       "4                                          170.38286                                                          \n",
       "\n",
       "   Weather forecast for the precipitation amount for the coming 1 hour at Bornholm | 9F7P/00/00/MET-Norway/forecast/precipitation_amount_acc | 128238  \\\n",
       "0                                           0.000000                                                                                                    \n",
       "1                                           0.269043                                                                                                    \n",
       "2                                           0.167969                                                                                                    \n",
       "3                                           0.000000                                                                                                    \n",
       "4                                           0.662842                                                                                                    \n",
       "\n",
       "   Weather forecast for the relativehumidity amount  at Bornholm | 9F7P/00/00/MET-Norway/forecast/relative_humidity_2m | 128254  \\\n",
       "0                                           0.848557                                                                              \n",
       "1                                           0.937904                                                                              \n",
       "2                                           0.974747                                                                              \n",
       "3                                           0.973976                                                                              \n",
       "4                                           0.989250                                                                              \n",
       "\n",
       "   Weather forecast for wind speed at Bornholm | 9F7P/00/00/MET-Norway/forecast/wind_speed | 128286  \\\n",
       "0                                           3.711973                                                  \n",
       "1                                           3.358219                                                  \n",
       "2                                           3.255157                                                  \n",
       "3                                           3.109769                                                  \n",
       "4                                           3.090981                                                  \n",
       "\n",
       "   Weather forecast for wind speed y_direction at Bornholm | 9F7P/00/00/MET-Norway/forecast/y_wind_10m | 128318  \\\n",
       "0                                           3.658367                                                              \n",
       "1                                           3.176009                                                              \n",
       "2                                           3.315285                                                              \n",
       "3                                           3.461883                                                              \n",
       "4                                           3.048118                                                              \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "2  ...   \n",
       "3  ...   \n",
       "4  ...   \n",
       "\n",
       "   Weather forecast for wind speed x_direction at Bornholm | 9F7P/00/00/MET-Norway/forecast/x_wind_10m | 128302  \\\n",
       "0                                           0.593647                                                              \n",
       "1                                           0.794102                                                              \n",
       "2                                           0.328136                                                              \n",
       "3                                          -0.328434                                                              \n",
       "4                                          -0.469315                                                              \n",
       "\n",
       "   Weather forecast for the air temperature at Bornholm | 9F7P/00/00/MET-Norway/forecast/air_temperature_2m | 128190  \\\n",
       "0                                          275.51404                                                                   \n",
       "1                                          275.36557                                                                   \n",
       "2                                          275.08374                                                                   \n",
       "3                                          274.86594                                                                   \n",
       "4                                          274.80240                                                                   \n",
       "\n",
       "   Observed maximum temperature past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/temp_max_past1h/06193 | 406592  \\\n",
       "0                                                NaN                                                                                      \n",
       "1                                                NaN                                                                                      \n",
       "2                                                NaN                                                                                      \n",
       "3                                                NaN                                                                                      \n",
       "4                                                NaN                                                                                      \n",
       "\n",
       "   Observed mean intensity of global radiation in the latest hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/radia_glob_past1h/06193 | 406672  \\\n",
       "0                                                NaN                                                                                                                \n",
       "1                                                NaN                                                                                                                \n",
       "2                                                NaN                                                                                                                \n",
       "3                                                NaN                                                                                                                \n",
       "4                                                NaN                                                                                                                \n",
       "\n",
       "   Observed minimum temperature past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/temp_min_past1h/06193 | 406608  \\\n",
       "0                                                NaN                                                                                      \n",
       "1                                                NaN                                                                                      \n",
       "2                                                NaN                                                                                      \n",
       "3                                                NaN                                                                                      \n",
       "4                                                NaN                                                                                      \n",
       "\n",
       "   Observed mean wind speed the past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/wind_speed_past1h/06193 | 406640  \\\n",
       "0                                                NaN                                                                                        \n",
       "1                                                NaN                                                                                        \n",
       "2                                                NaN                                                                                        \n",
       "3                                                NaN                                                                                        \n",
       "4                                                NaN                                                                                        \n",
       "\n",
       "   Observed mean humidity past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/humidity_past1h/06193 | 406576  \\\n",
       "0                                                NaN                                                                                \n",
       "1                                                NaN                                                                                \n",
       "2                                                NaN                                                                                \n",
       "3                                                NaN                                                                                \n",
       "4                                                NaN                                                                                \n",
       "\n",
       "   Observed mean temperature past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/temp_mean_past1h/06193 | 406560  \\\n",
       "0                                                NaN                                                                                    \n",
       "1                                                NaN                                                                                    \n",
       "2                                                NaN                                                                                    \n",
       "3                                                NaN                                                                                    \n",
       "4                                                NaN                                                                                    \n",
       "\n",
       "   Observed mean wind direction the past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/wind_dir_past1h/06193 | 406624  \\\n",
       "0                                                NaN                                                                                          \n",
       "1                                                NaN                                                                                          \n",
       "2                                                NaN                                                                                          \n",
       "3                                                NaN                                                                                          \n",
       "4                                                NaN                                                                                          \n",
       "\n",
       "   Observed accumulated precipitation the past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/precip_past1h/06193 | 406656  \n",
       "0                                                NaN                                                                                             \n",
       "1                                                NaN                                                                                             \n",
       "2                                                NaN                                                                                             \n",
       "3                                                NaN                                                                                             \n",
       "4                                                NaN                                                                                             \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>Hasle Common 10kV Lines Voltage | has_fel_10kvskinnespend | 804133</th>\n",
       "      <th>Hasle Vind Active Power | has_vin_effekt | 804123</th>\n",
       "      <th>Hasle Vind Current | has_vin_belastning | 804117</th>\n",
       "      <th>Weather forecast for the max air temperature for the coming 6 hours at Bornholm | 9F7P/00/00/MET-Norway/forecast/air_temperature_max | 128206</th>\n",
       "      <th>Weather forecast for wind direction at Bornholm | 9F7P/00/00/MET-Norway/forecast/wind_direction | 128270</th>\n",
       "      <th>Weather forecast for the precipitation amount for the coming 1 hour at Bornholm | 9F7P/00/00/MET-Norway/forecast/precipitation_amount_acc | 128238</th>\n",
       "      <th>Weather forecast for the relativehumidity amount  at Bornholm | 9F7P/00/00/MET-Norway/forecast/relative_humidity_2m | 128254</th>\n",
       "      <th>Weather forecast for wind speed at Bornholm | 9F7P/00/00/MET-Norway/forecast/wind_speed | 128286</th>\n",
       "      <th>Weather forecast for wind speed y_direction at Bornholm | 9F7P/00/00/MET-Norway/forecast/y_wind_10m | 128318</th>\n",
       "      <th>...</th>\n",
       "      <th>Weather forecast for wind speed x_direction at Bornholm | 9F7P/00/00/MET-Norway/forecast/x_wind_10m | 128302</th>\n",
       "      <th>Weather forecast for the air temperature at Bornholm | 9F7P/00/00/MET-Norway/forecast/air_temperature_2m | 128190</th>\n",
       "      <th>Observed maximum temperature past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/temp_max_past1h/06193 | 406592</th>\n",
       "      <th>Observed mean intensity of global radiation in the latest hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/radia_glob_past1h/06193 | 406672</th>\n",
       "      <th>Observed minimum temperature past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/temp_min_past1h/06193 | 406608</th>\n",
       "      <th>Observed mean wind speed the past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/wind_speed_past1h/06193 | 406640</th>\n",
       "      <th>Observed mean humidity past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/humidity_past1h/06193 | 406576</th>\n",
       "      <th>Observed mean temperature past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/temp_mean_past1h/06193 | 406560</th>\n",
       "      <th>Observed mean wind direction the past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/wind_dir_past1h/06193 | 406624</th>\n",
       "      <th>Observed accumulated precipitation the past hour at Hammer Odde Fyr - DMI station 06193 | 9F7P/7Q/XC/DMI/metObs/precip_past1h/06193 | 406656</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>10.505372</td>\n",
       "      <td>0.310046</td>\n",
       "      <td>19.138536</td>\n",
       "      <td>275.52020</td>\n",
       "      <td>189.13286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.848557</td>\n",
       "      <td>3.711973</td>\n",
       "      <td>3.658367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593647</td>\n",
       "      <td>275.51404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 01:00:00</td>\n",
       "      <td>10.499852</td>\n",
       "      <td>0.739963</td>\n",
       "      <td>42.792531</td>\n",
       "      <td>275.50630</td>\n",
       "      <td>191.73468</td>\n",
       "      <td>0.269043</td>\n",
       "      <td>0.937904</td>\n",
       "      <td>3.358219</td>\n",
       "      <td>3.176009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794102</td>\n",
       "      <td>275.36557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 02:00:00</td>\n",
       "      <td>10.440138</td>\n",
       "      <td>0.877331</td>\n",
       "      <td>50.523536</td>\n",
       "      <td>275.13600</td>\n",
       "      <td>184.39082</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.974747</td>\n",
       "      <td>3.255157</td>\n",
       "      <td>3.315285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328136</td>\n",
       "      <td>275.08374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 03:00:00</td>\n",
       "      <td>10.423414</td>\n",
       "      <td>0.842384</td>\n",
       "      <td>47.936477</td>\n",
       "      <td>274.88626</td>\n",
       "      <td>178.39856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973976</td>\n",
       "      <td>3.109769</td>\n",
       "      <td>3.461883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328434</td>\n",
       "      <td>274.86594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 04:00:00</td>\n",
       "      <td>10.401766</td>\n",
       "      <td>0.469178</td>\n",
       "      <td>28.816449</td>\n",
       "      <td>274.93670</td>\n",
       "      <td>170.38286</td>\n",
       "      <td>0.662842</td>\n",
       "      <td>0.989250</td>\n",
       "      <td>3.090981</td>\n",
       "      <td>3.048118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.469315</td>\n",
       "      <td>274.80240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 257
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load merged data from 2022  (neccessary for feature engineering like lags)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:50:01.911017Z",
     "start_time": "2024-10-29T17:50:01.832883Z"
    }
   },
   "source": [
    "# Load csv\n",
    "data22 = pd.read_csv('New Data/2022/Wind Data 22.csv')\n",
    "\n",
    "# Concatenate the dataframes\n",
    "data = pd.concat([data21, data22], join='inner', axis=0, ignore_index=True)\n",
    "\n",
    "# Ensure datetime format\n",
    "data['ts'] = pd.to_datetime(data['ts'])"
   ],
   "outputs": [],
   "execution_count": 258
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column cleaning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:50:01.926659Z",
     "start_time": "2024-10-29T17:50:01.911017Z"
    }
   },
   "source": [
    "\n",
    "# Use regex to remove everything starting from '|'\n",
    "data.columns = data.columns.str.replace(r'\\|.*', '', regex=True)\n",
    "nordpool.columns = nordpool.columns.str.replace(r'\\|.*', '', regex=True)\n",
    "energinet.columns = energinet.columns.str.replace(r'\\|.*', '', regex=True)\n",
    "\n",
    "# Use regex to remove everything starting from the word \"at\"\n",
    "data.columns = data.columns.str.replace(r'\\sat.*', '', regex=True)\n",
    "data.columns = data.columns.str.replace(r'Hasle', '', regex=True)\n",
    "data.columns = data.columns.str.replace(r'Vind', 'Wind', regex=True)\n",
    "\n",
    "# Strip columns\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "data.columns"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ts', 'Common 10kV Lines Voltage', 'Wind Active Power', 'Wind Current',\n",
       "       'Weather forecast for the max air temperature for the coming 6 hours',\n",
       "       'Weather forecast for wind direction',\n",
       "       'Weather forecast for the precipitation amount for the coming 1 hour',\n",
       "       'Weather forecast for the relativehumidity amount',\n",
       "       'Weather forecast for wind speed',\n",
       "       'Weather forecast for wind speed y_direction',\n",
       "       'Weather forecast for solar shortwave flux',\n",
       "       'Weather forecast for the minimum air temperature for the coming 6 hours',\n",
       "       'Weather forecast for wind speed x_direction',\n",
       "       'Weather forecast for the air temperature',\n",
       "       'Observed maximum temperature past hour',\n",
       "       'Observed mean intensity of global radiation in the latest hour',\n",
       "       'Observed minimum temperature past hour',\n",
       "       'Observed mean wind speed the past hour',\n",
       "       'Observed mean humidity past hour',\n",
       "       'Observed mean temperature past hour',\n",
       "       'Observed mean wind direction the past hour',\n",
       "       'Observed accumulated precipitation the past hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 259
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:50:02.105994Z",
     "start_time": "2024-10-29T17:50:01.926659Z"
    }
   },
   "source": [
    "# Resample the data by months ('M') and count missing values for each period\n",
    "data = data.set_index('ts')\n",
    "missing_per_month = data.isnull().resample('M').sum()\n",
    "# Reset\n",
    "data = data.reset_index()\n",
    "\n",
    "# Convert the resampled data into a long-form dataframe for easier plotting with Seaborn\n",
    "missing_per_month_long = missing_per_month.reset_index().melt(id_vars='ts', var_name='Feature', value_name='Missing Count')\n",
    "\n",
    "# Create the seaborn barplot\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.barplot(x='ts', y='Missing Count', hue='Feature', data=missing_per_month_long)\n",
    "plt.xticks(rotation=60)\n",
    "plt.title('Missing Value Counts per Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Missing Value Count')\n",
    "plt.legend(title='Feature', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[260], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Create the seaborn barplot\u001B[39;00m\n\u001B[0;32m     11\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m6\u001B[39m))\n\u001B[1;32m---> 12\u001B[0m \u001B[43msns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbarplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mts\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMissing Count\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mFeature\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmissing_per_month_long\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m plt\u001B[38;5;241m.\u001B[39mxticks(rotation\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m60\u001B[39m)\n\u001B[0;32m     14\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing Value Counts per Month\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\seaborn\\categorical.py:3147\u001B[0m, in \u001B[0;36mbarplot\u001B[1;34m(x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge, ax, **kwargs)\u001B[0m\n\u001B[0;32m   3141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbarplot\u001B[39m(x\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, hue\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, hue_order\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   3142\u001B[0m             estimator\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mmean, ci\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m95\u001B[39m, n_boot\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, units\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   3143\u001B[0m             orient\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, palette\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, saturation\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m.75\u001B[39m,\n\u001B[0;32m   3144\u001B[0m             errcolor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.26\u001B[39m\u001B[38;5;124m\"\u001B[39m, errwidth\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, capsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dodge\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   3145\u001B[0m             ax\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 3147\u001B[0m     plotter \u001B[38;5;241m=\u001B[39m \u001B[43m_BarPlotter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhue_order\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3148\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mci\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_boot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3149\u001B[0m \u001B[43m                          \u001B[49m\u001B[43morient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpalette\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msaturation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3150\u001B[0m \u001B[43m                          \u001B[49m\u001B[43merrcolor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcapsize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdodge\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3152\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ax \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3153\u001B[0m         ax \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mgca()\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\seaborn\\categorical.py:1614\u001B[0m, in \u001B[0;36m_BarPlotter.__init__\u001B[1;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001B[0m\n\u001B[0;32m   1609\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, y, hue, data, order, hue_order,\n\u001B[0;32m   1610\u001B[0m              estimator, ci, n_boot, units, seed,\n\u001B[0;32m   1611\u001B[0m              orient, color, palette, saturation, errcolor,\n\u001B[0;32m   1612\u001B[0m              errwidth, capsize, dodge):\n\u001B[0;32m   1613\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Initialize the plotter.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1614\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestablish_variables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1615\u001B[0m \u001B[43m                             \u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhue_order\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munits\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1616\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestablish_colors(color, palette, saturation)\n\u001B[0;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimate_statistic(estimator, ci, n_boot, seed)\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\seaborn\\categorical.py:155\u001B[0m, in \u001B[0;36m_CategoricalPlotter.establish_variables\u001B[1;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001B[0m\n\u001B[0;32m    152\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(err)\n\u001B[0;32m    154\u001B[0m \u001B[38;5;66;03m# Figure out the plotting orientation\u001B[39;00m\n\u001B[1;32m--> 155\u001B[0m orient \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfer_orient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morient\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;66;03m# Option 2a:\u001B[39;00m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;66;03m# We are plotting a single set of data\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;66;03m# ------------------------------------\u001B[39;00m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    161\u001B[0m \n\u001B[0;32m    162\u001B[0m     \u001B[38;5;66;03m# Determine where the data are\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\seaborn\\categorical.py:360\u001B[0m, in \u001B[0;36m_CategoricalPlotter.infer_orient\u001B[1;34m(self, x, y, orient)\u001B[0m\n\u001B[0;32m    358\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    359\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mh\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 360\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[43mis_not_numeric\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    361\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_not_numeric(x):\n\u001B[0;32m    362\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(no_numeric)\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\seaborn\\categorical.py:340\u001B[0m, in \u001B[0;36m_CategoricalPlotter.infer_orient.<locals>.is_not_numeric\u001B[1;34m(s)\u001B[0m\n\u001B[0;32m    338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_not_numeric\u001B[39m(s):\n\u001B[0;32m    339\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 340\u001B[0m         np\u001B[38;5;241m.\u001B[39masarray(s, dtype\u001B[38;5;241m=\u001B[39m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m)\n\u001B[0;32m    341\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m    342\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\numpy\\__init__.py:305\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(attr)\u001B[0m\n\u001B[0;32m    300\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    301\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn the future `np.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` will be defined as the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    302\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcorresponding NumPy scalar.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m __former_attrs__:\n\u001B[1;32m--> 305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(__former_attrs__[attr])\n\u001B[0;32m    307\u001B[0m \u001B[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001B[39;00m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001B[39;00m\n\u001B[0;32m    312\u001B[0m \u001B[38;5;66;03m# the full `numpy.testing` namespace\u001B[39;00m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtesting\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 260
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values Handling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_interpolated = data.interpolate(method='linear')\n",
    "\n",
    "# Set ts as index\n",
    "missing_before = data.isnull().sum()\n",
    "data = data.set_index('ts')\n",
    "# Interpolate missing values (time series-based)\n",
    "data = data.interpolate(method='time')\n",
    "# Reset index\n",
    "data = data.reset_index()\n",
    "missing_after = data.isnull().sum()\n",
    "\n",
    "missing_summary = pd.DataFrame({'Before': missing_before, 'After': missing_after})\n",
    "missing_summary"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features for Weather observation can not be interpolated as they occur in the very beginning. (01/01/21 - 15/01/21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lagged days\n",
    "- Quantiles from prev week\n",
    "- Wind power production is proportional to the cube of the wind speed: $P = \\frac{1}{2} \\rho \\pi r^2 V^3 $\n",
    "- Time-based features like day and hour\n",
    "\n",
    "\n",
    "Since 'Observed mean wind speed the past hour' and 'Observed Wind Speed Cubed' are highly correlated, we may encounter multicollinearity which can inflate variance estimates for regression coefficients. \n",
    "\n",
    "-> Lasso or Ridge regression or Nonlinear Regression needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data = data.rename(columns={'Wind Active Power': 'Wind Power'})\n",
    "\n",
    "# Shift by 24 hours for daily data\n",
    "data['Wind Power Lag1'] = data['Wind Power'].shift(24)\n",
    "data['Wind Power Lag2'] = data['Wind Power'].shift(48)\n",
    "data['Wind Power Lag3'] = data['Wind Power'].shift(72)\n",
    "\n",
    "# Rolling average for 1 week (=168h) for several quantiles\n",
    "data['Wind Power 0.50 Quantile'] = data['Wind Power'].rolling(window=168).quantile(0.5)\n",
    "data['Wind Power 0.75 Quantile'] = data['Wind Power'].rolling(window=168).quantile(0.75)\n",
    "data['Wind Power 0.95 Quantile'] = data['Wind Power'].rolling(window=168).quantile(0.95)\n",
    "\n",
    "# Cube of windspeed? (to capture non-linear relationships or wait for polynomial features?)\n",
    "data['Observed Wind Speed Cubed'] = data['Observed mean wind speed the past hour']**3\n",
    "data['Forecasted Wind Speed Cubed'] = data['Weather forecast for wind speed']**3\n",
    "\n",
    "# Time-based features\n",
    "data['Day'] = data['ts'].dt.dayofweek\n",
    "data['Hour'] = data['ts'].dt.hour\n",
    "data['Month'] = data['ts'].dt.month"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut down the data as weather_observation starts **15/01/2021** and ends **31/12/2021**?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Exclude all before 15/01/2021 for data\n",
    "start = pd.to_datetime('2021-01-15 16:00:00')\n",
    "data = data[data['ts'] >= start]\n",
    "# Exclude all after 31/12/2021 for data\n",
    "data = data[data['ts'] <= end]\n",
    "# Reset index\n",
    "data = data.reset_index(drop=True)\n",
    "# Check success\n",
    "len(data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check missing values\n",
    "data.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # Show me the missing values with ts\n",
    "# missing_values = data[data.isnull().any(axis=1)]\n",
    "# missing_values = missing_values[['ts', 'Observed mean wind speed the past hour']]\n",
    "# missing_values\n",
    "\n",
    "# # Drop rows with missing values\n",
    "# data = data.dropna()\n",
    "\n",
    "# # Adjust the index\n",
    "# data = data.reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Correlation matrix between features\n",
    "corr_matrix = data.corr()\n",
    "# print(corr_matrix)\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, linewidths=0.5, \n",
    "            cbar_kws={\"shrink\": 0.75}, square=True)\n",
    "plt.title('Correlation Matrix Heatmap', fontsize=18)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "palette1 = sns.color_palette(\"pastel\")\n",
    "palette2 = sns.color_palette(\"bright\")\n",
    "\n",
    "# Plot moving average of wind power vs time\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.lineplot(x=data['ts'], y=data['Wind Power'], label='Wind Power', color=palette1[0])\n",
    "sns.lineplot(x=data['ts'], y=data['Wind Power'].rolling(window=168).mean(), label='1 Week Moving Average', color=palette2[1])\n",
    "sns.lineplot(x=data['ts'], y=data['Wind Power'].rolling(window=336).mean(), label='2 Weeks Moving Average', color=palette2[2])\n",
    "sns.lineplot(x=data['ts'], y=data['Wind Power'].rolling(window=672).mean(), label='4 Weeks Moving Average', color=palette2[3])\n",
    "plt.title('Wind Power vs Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Wind Power')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot wind power vs wind current\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Wind Current', y='Wind Power', data=data, alpha=0.3)\n",
    "plt.plot([0, data['Wind Current'].max()], [0, data['Wind Power'].max()], color='red', linestyle='--')\n",
    "plt.title('Wind Power vs Wind Current')\n",
    "plt.xlabel('Wind Current')\n",
    "plt.ylabel('Wind Power')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot wind power vs weather forecast for wind speed\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='Weather forecast for wind speed', y='Wind Power', data=data, alpha=0.3)\n",
    "plt.plot([0, data['Weather forecast for wind speed'].max()], [0, data['Wind Power'].max()], color='red', linestyle='--')\n",
    "plt.title('Wind Power vs Weather Forecast for Wind Speed')\n",
    "plt.xlabel('Forecast mean wind speed')\n",
    "plt.ylabel('Wind Power')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split 80/20 train and test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define X, y\n",
    "X = data.drop(columns=['ts', 'Wind Power', 'Wind Current']) # Features\n",
    "ts = data['ts']\n",
    "y = data['Wind Power']\n",
    "\n",
    "# Split 80/20\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert scaled arrays back to DataFrames with original indices and column names\n",
    "X_train = pd.DataFrame(X_train, index=X.index[:split_index], columns=X.columns)\n",
    "X_test = pd.DataFrame(X_test, index=X.index[split_index:], columns=X.columns)\n",
    "y_train = pd.Series(y_train.values, index=y.index[:split_index])\n",
    "y_test = pd.Series(y_test.values, index=y.index[split_index:])\n",
    "\n",
    "# Confirm index alignment\n",
    "print(\"Train Index Equality:\", X_train.index.equals(y_train.index))\n",
    "print(\"Test Index Equality:\", X_test.index.equals(y_test.index))\n",
    "\n",
    "# Print shapes of the resulting datasets\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X2 = X including 'Wind Currentâ€˜ feature"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define X2\n",
    "X2 = data.drop(columns=['ts', 'Wind Power']) # Features\n",
    "\n",
    "# Split 80/20\n",
    "X_train2, X_test2 = X2[:split_index], X2[split_index:]\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "X_train2 = scaler.fit_transform(X_train2)\n",
    "X_test2 = scaler.transform(X_test2)\n",
    "\n",
    "# Convert scaled arrays back to DataFrames with original indices and column names\n",
    "X_train2 = pd.DataFrame(X_train2, index=X2.index[:split_index], columns=X2.columns)\n",
    "X_test2 = pd.DataFrame(X_test2, index=X2.index[split_index:], columns=X2.columns)\n",
    "\n",
    "# Confirm index alignment\n",
    "print(\"Train Index Equality:\", X_train2.index.equals(y_train.index))\n",
    "print(\"Test Index Equality:\", X_test2.index.equals(y_test.index))\n",
    "\n",
    "# Print shapes of the resulting datasets\n",
    "print(f\"Training data shape: {X_train2.shape}\")\n",
    "print(f\"Testing data shape: {X_test2.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # Define X, y\n",
    "# X = data.drop(columns=['ts', 'Wind Power']) # Features\n",
    "# ts = data['ts']\n",
    "# y = data['Wind Power']\n",
    "\n",
    "# # ts_test = ts_column[X_test.index] # if neccessary later\n",
    "\n",
    "# # Scale the features using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# # Get shapes\n",
    "# print(\"Train set:\", X_train.shape)\n",
    "# print(\"Test set:\", X_test.shape)\n",
    "\n",
    "# # Check indices\n",
    "# X_train = pd.DataFrame(X_train)\n",
    "# y_train = pd.Series(y_train)\n",
    "# X_test = pd.DataFrame(X_test)\n",
    "# y_test = pd.Series(y_test)\n",
    "\n",
    "# print(\"Train Index Equality:\", X_train.index.equals(y_train.index))\n",
    "# print(\"Test Index Equality:\", X_test.index.equals(y_test.index))\n",
    "\n",
    "# # # Align indices\n",
    "# # X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "# # y_test = pd.Series(y_test.values, index=y_test.index)\n",
    "# # X_test.index = y_test.index\n",
    "\n",
    "# print(\"Test Index Equality (2):\", X_test.index.equals(y_test.index))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Linear Regression (small sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of both approaches"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Step 3.1: Gradient Descent\n",
    "class LinearRegressionGD:\n",
    "\n",
    "    # attributes of the class\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000): \n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.theta = None  # Parameter vector (weights and bias)\n",
    "        self.cost_history = []  # To store cost function values over iterations\n",
    "    \n",
    "    # gradient descent algorithm\n",
    "    def fit(self, X, y): \n",
    "        # Ensure that X and y are NumPy arrays and convert them to float type\n",
    "        X = np.array(X, dtype=float)\n",
    "        y = np.array(y, dtype=float)\n",
    "\n",
    "        # Number of training samples (m) and number of features (n)\n",
    "        m, n = X.shape\n",
    "\n",
    "        # Add a bias (intercept) column of ones to the input matrix X\n",
    "        X_b = np.c_[np.ones((m, 1)), X]  # X_b is now (m, n+1) with the bias term\n",
    "        \n",
    "        # Initialize theta (parameters) with zeros\n",
    "        self.theta = np.zeros(n + 1)  # Including bias\n",
    "        \n",
    "        # Gradient Descent loop\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Predicted values (y_hat = X_b * theta)\n",
    "            y_pred = X_b.dot(self.theta)\n",
    "            \n",
    "            # Compute cost (MSE)\n",
    "            cost = (1 / (2 * m)) * np.sum((y_pred - y) ** 2)\n",
    "            self.cost_history.append(cost)  # Store cost for plotting\n",
    "\n",
    "            # Gradient (in matrix form)\n",
    "            gradient = (1 / m) * X_b.T.dot(y_pred - y)\n",
    "            \n",
    "            # Update the parameters theta\n",
    "            self.theta -= self.learning_rate * gradient\n",
    "    \n",
    "    # prediction function\n",
    "    def predict(self, X):\n",
    "        # Ensure that X is a NumPy array and convert it to float type\n",
    "        X = np.array(X, dtype=float)\n",
    "        \n",
    "        # Add a bias (intercept) column of ones to the input matrix X\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        \n",
    "        # Return predictions (y_pred = X_b * theta)\n",
    "        return X_b.dot(self.theta)\n",
    "\n",
    "################################################################################################################################################\n",
    "\n",
    "# Step 3.1: Closed-form solution (Normal Equation)\n",
    "def ClosedFormSolution(X, y):\n",
    "    # Ensure that X and y are NumPy arrays and convert them to float type\n",
    "    X = np.array(X, dtype=float)\n",
    "    y = np.array(y, dtype=float)\n",
    "    \n",
    "    # Add a bias (intercept) column of ones to the input matrix X\n",
    "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "    \n",
    "    # Normal equation: theta = (X.T * X)^(-1) * X.T * y\n",
    "    theta_best = np.linalg.pinv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "    \n",
    "    return theta_best"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of both approaches on small sample (e.g. 200 rows)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Small subset of train data\n",
    "X_train_small = np.array(X_train[100:300], dtype=float)  \n",
    "y_train_small = np.array(y_train[100:300], dtype=float)\n",
    "\n",
    "# Train using Gradient Descent\n",
    "gd_model = LinearRegressionGD(learning_rate=0.001, n_iterations=1000)\n",
    "gd_model.fit(X_train_small, y_train_small)\n",
    "y_pred_gd = gd_model.predict(X_train_small)\n",
    "\n",
    "# Train using Closed-Form Solution (Normal Equation)\n",
    "theta_best = ClosedFormSolution(X_train_small, y_train_small)\n",
    "X_b_small = np.c_[np.ones((X_train_small.shape[0], 1)), X_train_small]\n",
    "y_pred_closed_form = X_b_small.dot(theta_best)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a figure with three subplots: Gradient Descent progress, Actual vs. Predicted, Parity plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6)) \n",
    "\n",
    "# Subplot 1: Cost function over iterations (for Gradient Descent)\n",
    "axs[0].plot(gd_model.cost_history, label='Cost Function (MSE) over Iterations', color='b')\n",
    "axs[0].set_xlabel('Iterations')\n",
    "axs[0].set_ylabel('Mean Squared Error (MSE)')\n",
    "axs[0].set_title('Gradient Descent Progress')\n",
    "axs[0].legend()\n",
    "\n",
    "# Subplot 2: Actual vs Predicted values for both methods\n",
    "axs[1].plot(y_train_small, label='Actual Values', marker='o', color='g')\n",
    "axs[1].plot(y_pred_gd, label='Predicted Values (Gradient Descent)', marker='x', linestyle='--', color='r')\n",
    "axs[1].plot(y_pred_closed_form, label='Predicted Values (Closed Form)', marker='.', linestyle=':', color='b')\n",
    "axs[1].set_xlabel('Sample Index')\n",
    "axs[1].set_ylabel('Target Variable (y)')\n",
    "axs[1].set_title('Actual vs Predicted Values')\n",
    "axs[1].legend()\n",
    "\n",
    "# Subplot 3: Parity plot for both methods (Predicted vs Actual with 45-degree line)\n",
    "min_val = min(y_train_small.min(), y_pred_gd.min(), y_pred_closed_form.min())\n",
    "max_val = max(y_train_small.max(), y_pred_gd.max(), y_pred_closed_form.max())\n",
    "\n",
    "# Add the 45-degree perfect prediction line\n",
    "axs[2].plot([min_val, max_val], [min_val, max_val], 'k--', label='Perfect Prediction (45Â° Line)')\n",
    "\n",
    "# Scatter plot for Gradient Descent predictions\n",
    "axs[2].scatter(y_train_small, y_pred_gd, label='Gradient Descent', color='r', alpha=0.5)\n",
    "\n",
    "# Scatter plot for Closed-Form predictions\n",
    "axs[2].scatter(y_train_small, y_pred_closed_form, label='Closed Form', color='b', alpha=0.5)\n",
    "\n",
    "axs[2].set_xlabel('Actual Values')\n",
    "axs[2].set_ylabel('Predicted Values')\n",
    "axs[2].set_title('Parity Plot (Predicted vs Actual)')\n",
    "axs[2].legend()\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Verify that both solutions are close by comparing the predictions\n",
    "print(\"Gradient Descent Coefficients:\", gd_model.theta)\n",
    "print(\"Closed-Form Solution Coefficients:\", theta_best)\n",
    "# print(\"Are the predictions close? \", np.allclose(y_pred_gd, y_pred_closed_form, atol=1e-1))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Linear Regression (large sample)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Closed-Form Solution (Normal Equation)\n",
    "theta_best_full = ClosedFormSolution(X_train, y_train) # Compute on the train data\n",
    "X_b_full = np.c_[np.ones((X_test.shape[0], 1)), X_test] # Predictions on the test / unseen data!\n",
    "y_test_pred_closed_form = X_b_full.dot(theta_best_full)\n",
    "\n",
    "# Train using Gradient Descent on full dataset\n",
    "gd_model = LinearRegressionGD(learning_rate=0.00001, n_iterations=500000)  \n",
    "gd_model.fit(X_train, y_train) # Compute on the train data\n",
    "y_test_pred_gd = gd_model.predict(X_test) # Predictions on the test / unseen data!\n",
    "\n",
    "# Convert predictions to pandas Series with y_test's original index\n",
    "y_test_pred_closed_form = pd.Series(y_test_pred_closed_form, index=y_test.index)\n",
    "y_test_pred_gd = pd.Series(y_test_pred_gd, index=y_test.index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a figure with three subplots side by side\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))  # 1 row, 3 columns\n",
    "\n",
    "# Subplot 1: Cost function over iterations (for Gradient Descent)\n",
    "axs[0].plot(gd_model.cost_history, label='Cost Function (MSE) over Iterations', color='b')\n",
    "axs[0].set_xlabel('Iterations')\n",
    "axs[0].set_ylabel('Mean Squared Error (MSE)')\n",
    "axs[0].set_title('Gradient Descent Progress')\n",
    "axs[0].legend()\n",
    "\n",
    "# Subplot 2: Actual vs Predicted values for both methods\n",
    "axs[1].plot(y_test[500:1000], label='Actual Values', marker='o', color='g')\n",
    "axs[1].plot(y_test_pred_gd[500:1000], label='Predicted Values (Gradient Descent)', marker='x', linestyle='--', color='r')\n",
    "axs[1].plot(y_test_pred_closed_form[500:1000], label='Predicted Values (Closed Form)', marker='.', linestyle=':', color='b')\n",
    "axs[1].set_xlabel('Sample Index')\n",
    "axs[1].set_ylabel('Target Variable (y)')\n",
    "axs[1].set_title('Actual vs Predicted Values (Test Set)')\n",
    "axs[1].legend()\n",
    "\n",
    "# Subplot 3: Parity plot for both methods (Predicted vs Actual with 45-degree line)\n",
    "min_val = min(y_test.min(), y_test_pred_gd.min(), y_test_pred_closed_form.min())\n",
    "max_val = max(y_test.max(), y_test_pred_gd.max(), y_test_pred_closed_form.max())\n",
    "\n",
    "# Add the 45-degree perfect prediction line\n",
    "axs[2].plot([min_val, max_val], [min_val, max_val], label='Perfect Prediction (45Â° Line)', linestyle='-', linewidth=4 ,color='g')\n",
    "# Scatter plot for Gradient Descent predictions\n",
    "axs[2].scatter(y_test, y_test_pred_gd, label='Gradient Descent', color='r', alpha=0.4)\n",
    "# Scatter plot for Closed-Form predictions\n",
    "axs[2].scatter(y_test, y_test_pred_closed_form, label='Closed Form', color='b', alpha=0.4)\n",
    "\n",
    "axs[2].set_xlim(-0.2,9)\n",
    "axs[2].set_xlabel('Actual Values')\n",
    "axs[2].set_ylabel('Predicted Values')\n",
    "axs[2].set_title('Parity Plot (Predicted vs Actual)')\n",
    "axs[2].legend()\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Output the coefficients for both methods\n",
    "print(\"Gradient Descent Coefficients:\", gd_model.theta)\n",
    "print(\"Closed-Form Solution Coefficients:\", theta_best_full)\n",
    "\n",
    "# Compare the predictions and check if they are close\n",
    "print(\"Are the predictions close? \", np.allclose(y_test_pred_gd, y_test_pred_closed_form))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Step 3.3: Evaluate the models \n",
    "rmse_gd = np.sqrt(mean_squared_error(y_test, y_test_pred_gd))\n",
    "r2_gd = r2_score(y_test, y_test_pred_gd)\n",
    "print(f'Mean Squared Error (Gradient Descent): {rmse_gd}')\n",
    "print(f'R-squared (Gradient Descent): {r2_gd}')\n",
    "\n",
    "rmse_closed_form = np.sqrt(mean_squared_error(y_test, y_test_pred_closed_form))\n",
    "r2_closed_form = r2_score(y_test, y_test_pred_closed_form)\n",
    "print(f'Mean Squared Error (Closed Form): {rmse_closed_form}')\n",
    "print(f'R-squared (Closed Form): {r2_closed_form}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get coefficients from the Linear Regression model\n",
    "cols = ['Intercept'] + list(X_train.columns)\n",
    "lr_coefficients_df = pd.DataFrame({ 'Feature': cols, 'Coefficient (GD)': gd_model.theta, 'Coefficient (Closed Form)': theta_best_full})\n",
    "lr_coefficients_df.T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # Step 3.3: Evaluate the model on the testing dataset\n",
    "# X_b_test = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "# y_test_pred = X_b_test.dot(theta_best_full)\n",
    "\n",
    "# # Evaluation Metrics\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "# mae = mean_absolute_error(y_test, y_test_pred)\n",
    "# r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "# print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "# print(f\"R-squared (RÂ²): {r2}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3: Linear Regression (large sample + Wind Current)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Closed-Form Solution (Normal Equation)\n",
    "theta_best_full2 = ClosedFormSolution(X_train2, y_train) # Compute on the train data\n",
    "X_b_full2 = np.c_[np.ones((X_test.shape[0], 1)), X_test2] # Predictions on the test / unseen data!\n",
    "y_test_pred_closed_form2 = X_b_full2.dot(theta_best_full2)\n",
    "\n",
    "# Train using Gradient Descent on full dataset\n",
    "gd_model2 = LinearRegressionGD(learning_rate=0.00001, n_iterations=500000)  \n",
    "gd_model2.fit(X_train2, y_train) # Compute on the train data\n",
    "y_test_pred_gd2 = gd_model2.predict(X_test2) # Predictions on the test / unseen data!\n",
    "\n",
    "# Convert predictions to pandas Series with y_test's original index\n",
    "y_test_pred_closed_form2 = pd.Series(y_test_pred_closed_form2, index=y_test.index)\n",
    "y_test_pred_gd2 = pd.Series(y_test_pred_gd2, index=y_test.index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a figure with three subplots side by side\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))  # 1 row, 3 columns\n",
    "\n",
    "# Subplot 1: Cost function over iterations (for Gradient Descent)\n",
    "axs[0].plot(gd_model2.cost_history, label='Cost Function (MSE) over Iterations', color='b')\n",
    "axs[0].set_xlabel('Iterations')\n",
    "axs[0].set_ylabel('Mean Squared Error (MSE)')\n",
    "axs[0].set_title('Gradient Descent Progress')\n",
    "axs[0].legend()\n",
    "\n",
    "# Subplot 2: Actual vs Predicted values for both methods\n",
    "axs[1].plot(y_test, label='Actual Values', marker='o', color='g')\n",
    "axs[1].plot(y_test_pred_gd2, label='Predicted Values (Gradient Descent)', marker='x', linestyle='--', color='r')\n",
    "axs[1].plot(y_test_pred_closed_form2, label='Predicted Values (Closed Form)', marker='.', linestyle=':', color='b')\n",
    "axs[1].set_xlabel('Sample Index')\n",
    "axs[1].set_ylabel('Target Variable (y)')\n",
    "axs[1].set_title('Actual vs Predicted Values (Test Set)')\n",
    "axs[1].legend()\n",
    "\n",
    "# Subplot 3: Parity plot for both methods (Predicted vs Actual with 45-degree line)\n",
    "min_val = min(y_test.min(), y_test_pred_gd2.min(), y_test_pred_closed_form2.min())\n",
    "max_val = max(y_test.max(), y_test_pred_gd2.max(), y_test_pred_closed_form2.max())\n",
    "\n",
    "# Add the 45-degree perfect prediction line\n",
    "axs[2].plot([min_val, max_val], [min_val, max_val], label='Perfect Prediction (45Â° Line)', linestyle='-', linewidth=4 ,color='g')\n",
    "# Scatter plot for Gradient Descent predictions\n",
    "axs[2].scatter(y_test, y_test_pred_gd2, label='Gradient Descent', color='r', alpha=0.4)\n",
    "# Scatter plot for Closed-Form predictions\n",
    "axs[2].scatter(y_test, y_test_pred_closed_form2, label='Closed Form', color='b', alpha=0.4)\n",
    "\n",
    "axs[2].set_xlim(-0.2,9)\n",
    "axs[2].set_xlabel('Actual Values')\n",
    "axs[2].set_ylabel('Predicted Values')\n",
    "axs[2].set_title('Parity Plot (Predicted vs Actual)')\n",
    "axs[2].legend()\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Output the coefficients for both methods\n",
    "print(\"Gradient Descent Coefficients:\", gd_model2.theta)\n",
    "print(\"Closed-Form Solution Coefficients:\", theta_best_full2)\n",
    "\n",
    "# Compare the predictions and check if they are close\n",
    "print(\"Are the predictions close? \", np.allclose(y_test_pred_gd2, y_test_pred_closed_form2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Step 3.3: Evaluate the models \n",
    "rmse_gd2 = np.sqrt(mean_squared_error(y_test, y_test_pred_gd2))\n",
    "r2_gd2 = r2_score(y_test, y_test_pred_gd2)\n",
    "print(f'Mean Squared Error (Gradient Descent): {rmse_gd2}')\n",
    "print(f'R-squared (Gradient Descent): {r2_gd2}')\n",
    "\n",
    "rmse_closed_form2 = np.sqrt(mean_squared_error(y_test, y_test_pred_closed_form2))\n",
    "r2_closed_form2 = r2_score(y_test, y_test_pred_closed_form2)\n",
    "print(f'Mean Squared Error (Closed Form): {rmse_closed_form2}')\n",
    "print(f'R-squared (Closed Form): {r2_closed_form2}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get coefficients from the Linear Regression model\n",
    "cols = ['Intercept'] + list(X_train2.columns)\n",
    "lr_coefficients_df2 = pd.DataFrame({ 'Feature': cols, 'Coefficient (GD)': gd_model2.theta, 'Coefficient (Closed Form)': theta_best_full2})\n",
    "lr_coefficients_df2.T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Non-linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4.1: Non-linear Regression through feature modification\n",
    "\n",
    "Step 4.2: Non-linear Regression through weight modification"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 4.1: Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Train the regression model on polynomial features\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_train_poly, y_train)\n",
    "y_pred_poly = model_poly.predict(X_test_poly)\n",
    "\n",
    "################################################################################################################################################\n",
    "\n",
    "# Step 4.2: Define random weights and fit the weighted linear regression model\n",
    "weights = np.random.rand(X_train.shape[0])  # Random weights for demonstration -> how to set up \n",
    "\n",
    "# Train the regression model with specified weights\n",
    "model_weighted = LinearRegression()\n",
    "model_weighted.fit(X_train, y_train, sample_weight=weights)\n",
    "y_pred_weighted = model_weighted.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4.3: Evaluation of the models with R^2 & RMSE"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Step 4.3: Evaluation metrics for all models\n",
    "rmse_linear = np.sqrt(mean_squared_error(y_test, y_test_pred_gd))\n",
    "r2_linear = r2_score(y_test, y_test_pred_gd)\n",
    "rmse_poly = np.sqrt(mean_squared_error(y_test, y_pred_poly))\n",
    "r2_poly = r2_score(y_test, y_pred_poly)\n",
    "rmse_weighted = np.sqrt(mean_squared_error(y_test, y_pred_weighted))\n",
    "r2_weighted = r2_score(y_test, y_pred_weighted)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Linear Model R-Squared: {r2_linear}\")\n",
    "print(f\"Polynomial Model R-Squared: {r2_poly}\")\n",
    "print(f\"Weighted Model R-Squared: {r2_weighted}\")\n",
    "\n",
    "# Convert predictions to pandas Series with y_test's original index\n",
    "y_pred_poly = pd.Series(y_pred_poly, index=y_test.index)\n",
    "y_pred_weighted = pd.Series(y_pred_weighted, index=y_test.index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a figure with six subplots (3x2): One row for actual vs. predicted, another for parity plots\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 12))  # 2 rows, 3 columns\n",
    "\n",
    "### First row: Actual vs. Predicted values\n",
    "# Subplot 1: Actual vs Predicted for Linear Regression (from Step 3)\n",
    "axs[0, 0].plot(y_test, label='Actual Values', marker='o', color='g')\n",
    "axs[0, 0].plot(y_test_pred_gd, label='Predicted (Linear)', marker='x', linestyle='--', color='b')\n",
    "axs[0, 0].set_xlabel('Sample Index')\n",
    "axs[0, 0].set_ylabel('Target Variable (y)')\n",
    "axs[0, 0].set_title('Linear Regression')\n",
    "axs[0, 0].legend()\n",
    "\n",
    "# Subplot 2: Actual vs Predicted for Polynomial Regression (Step 4.1)\n",
    "axs[0, 1].plot(y_test, label='Actual Values', marker='o', color='g')\n",
    "axs[0, 1].plot(y_pred_poly, label='Predicted (Polynomial)', marker='x', linestyle='--', color='r')\n",
    "axs[0, 1].set_xlabel('Sample Index')\n",
    "axs[0, 1].set_ylabel('Target Variable (y)')\n",
    "axs[0, 1].set_title('Polynomial Regression (Degree 2)')\n",
    "axs[0, 1].legend()\n",
    "\n",
    "# Subplot 3: Actual vs Predicted for Weighted Regression (Step 4.2)\n",
    "axs[0, 2].plot(y_test, label='Actual Values', marker='o', color='g')\n",
    "axs[0, 2].plot(y_pred_weighted, label='Predicted (Weighted)', marker='x', linestyle='--', color='orange')\n",
    "axs[0, 2].set_xlabel('Sample Index')\n",
    "axs[0, 2].set_ylabel('Target Variable (y)')\n",
    "axs[0, 2].set_title('Weighted Regression')\n",
    "axs[0, 2].legend()\n",
    "\n",
    "### Second row: Parity plots (Predicted vs Actual, with 45-degree line)\n",
    "min_val = min(y_test.min(), y_test_pred_gd.min(), y_pred_poly.min(), y_pred_weighted.min())\n",
    "max_val = max(y_test.max(), y_test_pred_gd.max(), y_pred_poly.max(), y_pred_weighted.max())\n",
    "\n",
    "# Subplot 4: Parity plot for Linear Regression\n",
    "axs[1, 0].scatter(y_test, y_test_pred_gd, color='b', alpha=0.5, label='Linear Regression')\n",
    "# axs[1, 0].plot([min_val, max_val], [min_val, max_val], 'k--', label='Perfect Prediction')\n",
    "axs[1, 0].plot([min_val, max_val], [min_val, max_val], label='Perfect Prediction', linestyle='-', linewidth=4 ,color='g')\n",
    "axs[1, 0].set_xlabel('Actual Values')\n",
    "axs[1, 0].set_ylabel('Predicted Values')\n",
    "axs[1, 0].set_title('Linear Regression Parity Plot')\n",
    "axs[1, 0].set_xlim(-0.2,9)\n",
    "axs[1, 0].legend()\n",
    "\n",
    "# Subplot 5: Parity plot for Polynomial Regression\n",
    "axs[1, 1].scatter(y_test, y_pred_poly, color='r', alpha=0.5, label='Polynomial Regression')\n",
    "# axs[1, 1].plot([min_val, max_val], [min_val, max_val], 'k--', label='Perfect Prediction')\n",
    "axs[1, 1].plot([min_val, max_val], [min_val, max_val], label='Perfect Prediction', linestyle='-', linewidth=4 ,color='g')\n",
    "axs[1, 1].set_xlabel('Actual Values')\n",
    "axs[1, 1].set_ylabel('Predicted Values')\n",
    "axs[1, 1].set_title('Polynomial Regression Parity Plot')\n",
    "axs[1, 1].set_xlim(-0.2,9)\n",
    "axs[1, 1].legend()\n",
    "\n",
    "# Subplot 6: Parity plot for Weighted Regression\n",
    "axs[1, 2].scatter(y_test, y_pred_weighted, color='orange', alpha=0.5, label='Weighted Regression')\n",
    "# axs[1, 2].plot([min_val, max_val], [min_val, max_val], 'k--', label='Perfect Prediction')\n",
    "axs[1, 2].plot([min_val, max_val], [min_val, max_val], label='Perfect Prediction', linestyle='-', linewidth=4 ,color='g')\n",
    "axs[1, 2].set_xlabel('Actual Values')\n",
    "axs[1, 2].set_ylabel('Predicted Values')\n",
    "axs[1, 2].set_title('Weighted Regression Parity Plot')\n",
    "axs[1, 2].set_xlim(-0.2,9)\n",
    "axs[1, 2].legend()\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Lasso + Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso + Ridge (Package)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize Lasso with alpha (regularization strength) parameter \n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train2, y_train) # including Wind Current\n",
    "y_pred_lasso = lasso.predict(X_test2)\n",
    "\n",
    "# Evaluate the Lasso model\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_lasso}\")\n",
    "print(f\"R-squared (RÂ²): {r2_lasso}\")\n",
    "\n",
    "# Get coefficients (non-zero ones indicate selected features)\n",
    "print(\"#Lasso Coefficients != 0:\", np.sum(lasso.coef_ != 0))\n",
    "print(\"Lasso Coefficients:\", lasso.coef_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert predictions to pandas Series with y_test's original index\n",
    "y_pred_lasso = pd.Series(y_pred_lasso, index=y_test.index)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(y_test, label='Actual Values', color='g', alpha=0.5)\n",
    "plt.plot(y_pred_lasso, label='Predicted Values (Lasso)', color='r') # linestyle='--',\n",
    "plt.plot(y_test_pred_closed_form, label='Predicted Values (Closed Form)', color='b') # linestyle=':',\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Target Variable (y)')\n",
    "plt.title('Actual vs Predicted Values (Test Set)')\n",
    "plt.legend()\n",
    "plt.xlim(6720, 8410)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO with Cross-Validation to select optimal alpha value"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define a range of alpha values to test\n",
    "alpha_values = np.logspace(-4, 0, num=20)\n",
    "\n",
    "# Set up the Lasso model with CV\n",
    "lasso2 = Lasso()\n",
    "param_grid = {'alpha': alpha_values}\n",
    "grid_search = GridSearchCV(estimator=lasso2, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best alpha\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "print(f\"Optimal Alpha: {best_alpha}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Lasso Model\n",
    "lasso3 = Lasso(alpha=best_alpha)\n",
    "lasso3.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso3.predict(X_test)\n",
    "\n",
    "# Evaluate Lasso model\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_lasso}\")\n",
    "print(f\"R-squared (RÂ²): {r2_lasso}\")\n",
    "\n",
    "# Coefficients\n",
    "print(\"#Lasso Coefficients != 0:\", np.sum(lasso3.coef_ != 0))\n",
    "lasso_coefficients_df = pd.DataFrame({ 'Feature': X_train.columns, 'Coefficient': lasso3.coef_}) \n",
    "lasso_coefficients_df = lasso_coefficients_df[lasso_coefficients_df['Coefficient'] != 0] # Filter non-zeros\n",
    "lasso_coefficients_df.T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 5.5: Analyze how regularization affects Lasso coefficients\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train baseline Linear Regression for coefficient comparison\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "baseline_coefs = pd.Series(linear_model.coef_, index=X_train.columns, name=\"Baseline Linear Regression Coefs\")\n",
    "\n",
    "# Compare baseline vs Lasso coefficients\n",
    "lasso_coefs = pd.Series(lasso3.coef_, index=X_train.columns, name=\"Lasso Coefs (Optimal Alpha)\")\n",
    "lasso_comparison = pd.concat([baseline_coefs, lasso_coefs], axis=1)\n",
    "lasso_comparison['Change (Lasso)'] = lasso_comparison['Lasso Coefs (Optimal Alpha)'] - lasso_comparison['Baseline Linear Regression Coefs']\n",
    "\n",
    "print(\"Lasso Coefficients Comparison (showing features shrunk by regularization):\")\n",
    "print(lasso_comparison[lasso_comparison['Lasso Coefs (Optimal Alpha)'] == 0])  # Features set to zero by Lasso\n",
    "print(\"\\nTop features with significant change under Lasso regularization:\")\n",
    "print(lasso_comparison[lasso_comparison['Change (Lasso)'].abs() > 0.1])  # Adjust threshold based on feature scale\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 5.5: Analyze how regularization affects Lasso coefficients\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train baseline Linear Regression for coefficient comparison\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "baseline_coefs = pd.Series(linear_model.coef_, index=X_train.columns, name=\"Baseline Linear Regression Coefs\")\n",
    "\n",
    "# Compare baseline vs Lasso coefficients\n",
    "lasso_coefs = pd.Series(lasso3.coef_, index=X_train.columns, name=\"Lasso Coefs (Optimal Alpha)\")\n",
    "lasso_comparison = pd.concat([baseline_coefs, lasso_coefs], axis=1)\n",
    "lasso_comparison['Change (Lasso)'] = lasso_comparison['Lasso Coefs (Optimal Alpha)'] - lasso_comparison['Baseline Linear Regression Coefs']\n",
    "\n",
    "print(\"Lasso Coefficients Comparison (showing features shrunk by regularization):\")\n",
    "print(lasso_comparison[lasso_comparison['Lasso Coefs (Optimal Alpha)'] == 0])  # Features set to zero by Lasso\n",
    "print(\"\\nTop features with significant change under Lasso regularization:\")\n",
    "print(lasso_comparison[lasso_comparison['Change (Lasso)'].abs() > 0.1])  # Adjust threshold based on feature scale\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Build Ridge model\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred = ridge.predict(X_train)\n",
    "\n",
    "# Evaluate Ridge model\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_test_reg, y_pred))\n",
    "mae_ridge = mean_absolute_error(y_test_reg, y_pred)\n",
    "r2_ridge = r2_score(y_test_reg, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_ridge}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_ridge}\")\n",
    "print(f\"R-squared (RÂ²): {r2_ridge}\")\n",
    "\n",
    "# Coefficients\n",
    "print(\"#Ridge Coefficients != 0:\", np.sum(ridge.coef_ != 0))\n",
    "# Save coefficients\n",
    "theta_best_ridge = np.append(ridge.intercept_, ridge.coef_)\n",
    "ridge_coefficients_df = pd.DataFrame({ 'Feature': X_train_reg.columns, 'Coefficient': ridge.coef_})\n",
    "ridge_coefficients_df = ridge_coefficients_df[ridge_coefficients_df['Coefficient'] != 0] # Filter non-zeros\n",
    "ridge_coefficients_df.T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def ridge_closed_form_solution(X, y, alpha=1.0):\n",
    "    # Ensure X and y are NumPy arrays and convert them to float type\n",
    "    X = np.array(X, dtype=float)\n",
    "    y = np.array(y, dtype=float)\n",
    "\n",
    "    # Add a bias (intercept) column of ones to the input matrix X\n",
    "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "    # Normal equation: theta = (X.T * X + alpha * I)^(-1) * X.T * y\n",
    "    identity_matrix = np.eye(X_b.shape[1])\n",
    "    theta_best = np.linalg.inv(X_b.T.dot(X_b) + alpha * identity_matrix).dot(X_b.T).dot(y)\n",
    "\n",
    "    return theta_best"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 5.5: Analyze how regularization affects Ridge coefficients\n",
    "\n",
    "# Get Ridge coefficients and compare them to baseline\n",
    "ridge_coefs = pd.Series(ridge.coef_, index=X_train.columns, name=\"Ridge Coefs (Optimal Alpha)\")\n",
    "ridge_comparison = pd.concat([baseline_coefs, ridge_coefs], axis=1)\n",
    "ridge_comparison['Change (Ridge)'] = ridge_comparison['Ridge Coefs (Optimal Alpha)'] - ridge_comparison['Baseline Linear Regression Coefs']\n",
    "\n",
    "print(\"\\nRidge Coefficients Comparison (highlighting features most affected):\")\n",
    "print(ridge_comparison[ridge_comparison['Change (Ridge)'].abs() > 0.1])  # Adjust threshold as needed\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.1: Linear Regression with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Linear Regression with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class LinearRegressionWithRegularization(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000, alpha=0.1, regularization=\"l1\"):\n",
    "        # Hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.alpha = alpha  # Regularization strength\n",
    "        self.regularization = regularization\n",
    "        self.theta = None  # Parameters (weights and bias)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Ensure X and y are NumPy arrays\n",
    "        X = np.array(X, dtype=float)\n",
    "        y = np.array(y, dtype=float)\n",
    "\n",
    "        # Add a bias (intercept) column of ones to the input matrix X\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]  # X_b now includes the bias term\n",
    "        m, n = X_b.shape\n",
    "\n",
    "        # Initialize theta\n",
    "        self.theta = np.zeros(n)\n",
    "\n",
    "        # Gradient Descent loop\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Predicted values (y_hat = X_b * theta)\n",
    "            y_pred = X_b.dot(self.theta)\n",
    "\n",
    "            # Compute the gradient\n",
    "            gradient = (1 / m) * X_b.T.dot(y_pred - y)\n",
    "\n",
    "            # Apply regularization to the gradient (skip bias term)\n",
    "            if self.regularization == \"l2\":\n",
    "                # L2 Regularization (Ridge): (MSE + L2 penalty)\n",
    "                gradient[1:] += 2 * self.alpha * self.theta[1:]\n",
    "            elif self.regularization == \"l1\":\n",
    "                # L1 Regularization (LASSO): (MSE + L1 penalty)\n",
    "                for j in range(1, n):\n",
    "                    if self.theta[j] > 0:\n",
    "                        gradient[j] += self.alpha\n",
    "                    elif self.theta[j] < 0:\n",
    "                        gradient[j] -= self.alpha\n",
    "\n",
    "            # Update parameters\n",
    "            self.theta -= self.learning_rate * gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Ensure X is a NumPy array and convert it to float type\n",
    "        X = np.array(X, dtype=float)\n",
    "\n",
    "        # Add a bias (intercept) column of ones to the input matrix X\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "        # Return predictions (y_pred = X_b * theta)\n",
    "        return X_b.dot(self.theta)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test model for L1 (LASSO)\n",
    "model_l1 = LinearRegressionWithRegularization(alpha=0.05, regularization=\"l1\")\n",
    "model_l1.fit(X_train, y_train)\n",
    "y_pred_l1 = model_l1.predict(X_test)\n",
    "\n",
    "# Evaluate L1 model\n",
    "r2_l1 = r2_score(y_test, y_pred_l1)\n",
    "print(f\"R-squared (Lasso): {r2_l1}\")\n",
    "\n",
    "# Test model for L2 (RIDGE)\n",
    "model_l2 = LinearRegressionWithRegularization(alpha=0.05, regularization=\"l2\")\n",
    "model_l2.fit(X_train, y_train)\n",
    "y_pred_l2 = model_l2.predict(X_test)\n",
    "\n",
    "# Evaluate L2 model\n",
    "r2_l2 = r2_score(y_test, y_pred_l2)\n",
    "print(f\"R-squared (Ridge): {r2_l2}\")\n",
    "\n",
    "# Convert predictions to pandas Series with y_test's original index\n",
    "y_pred_l1 = pd.Series(y_pred_l1, index=y_test.index)\n",
    "y_pred_l2 = pd.Series(y_pred_l2, index=y_test.index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to find the optimal alpha value with Parameter GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize the model\n",
    "model_lasso = LinearRegressionWithRegularization(regularization=\"l1\", learning_rate=0.001, n_iterations=10000)\n",
    "# Define a range of alpha values to test\n",
    "alpha_values = np.logspace(-4, 0, num=20)\n",
    "param_grid = {'alpha': alpha_values}\n",
    "\n",
    "# Set up the Lasso model with CV\n",
    "grid_search = GridSearchCV(estimator=model_lasso, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best alpha\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "print(f\"Optimal Alpha: {best_alpha}\")\n",
    "\n",
    "# Best model after grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_l1 = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2_l1 = r2_score(y_test, y_pred_l1)\n",
    "\n",
    "# Coefficients\n",
    "print(\"#Lasso Coefficients != 0:\", np.sum(best_model.theta != 0))\n",
    "cols = ['Intercept'] + list(X_train.columns)\n",
    "lasso_coefficients_df = pd.DataFrame({ 'Feature': cols, 'Coefficient': best_model.theta})\n",
    "lasso_coefficients_df = lasso_coefficients_df[lasso_coefficients_df['Coefficient'] != 0] # Filter non-zeros\n",
    "lasso_coefficients_df.T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.2: Non-Linear Regression with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class PolynomialRegressionWithRegularization(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, degree, learning_rate=0.01, n_iterations=1000, alpha=0.1, regularization=\"l1\"):\n",
    "        # Hyperparameters\n",
    "        self.degree = degree\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.alpha = alpha # = Regularization strength\n",
    "        self.regularization = regularization\n",
    "        self.theta = None\n",
    "\n",
    "    def _polynomial_features(self, X):\n",
    "        # Generate polynomial features up to specified degree\n",
    "        X_poly = np.ones((X.shape[0], 1)) # Bias term\n",
    "        for d in range(1, self.degree + 1):\n",
    "            X_poly = np.c_[X_poly, X ** d]\n",
    "        return X_poly\n",
    "\n",
    "    # Gradient Descent Fit\n",
    "    def fit(self, X, y):\n",
    "        # Generate polynomial features\n",
    "        X_poly = self._polynomial_features(X)\n",
    "        # Number of training samples (m) and number of features (n)\n",
    "        m, n = X_poly.shape\n",
    "        # Initialize theta\n",
    "        self.theta = np.zeros(n)\n",
    "        \n",
    "        # Gradient Descent loop\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Predicted values (y_hat = X_b * theta)\n",
    "            y_pred = X_poly.dot(self.theta)\n",
    "            \n",
    "            # Compute the gradient\n",
    "            gradient = (1 / m) * X_poly.T.dot(y_pred - y)\n",
    "            \n",
    "            # Apply regularization to the gradient (& skip bias term)\n",
    "            if self.regularization == \"l2\":\n",
    "                # L2 Regularization (Ridge): (MSE + L2 penalty)\n",
    "                gradient[1:] += 2 * self.alpha * self.theta[1:]\n",
    "            elif self.regularization == \"l1\":\n",
    "                # L1 Regularization (LASSO): (MSE + L1 penalty)\n",
    "                for j in range(1, n):\n",
    "                    if self.theta[j] > 0:\n",
    "                        gradient[j] += self.alpha\n",
    "                    elif self.theta[j] < 0:\n",
    "                        gradient[j] -= self.alpha\n",
    "            \n",
    "            # Update parameters\n",
    "            self.theta -= self.learning_rate * gradient\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Generate polynomial features (including bias term)\n",
    "        X_poly = self._polynomial_features(X)\n",
    "        \n",
    "        # Return predictions\n",
    "        return X_poly.dot(self.theta)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEGREE=3 doesnt work / loads forever!!!!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test model for L1 (LASSO)\n",
    "model_nl1 = PolynomialRegressionWithRegularization(degree=2, alpha=0.05, learning_rate=0.001, n_iterations=10000, regularization=\"l1\")\n",
    "model_nl1.fit(X_train, y_train)\n",
    "y_pred_nl1 = model_nl1.predict(X_test)\n",
    "\n",
    "# Evaluate L1 model\n",
    "r2_nl1 = r2_score(y_test, y_pred_nl1)\n",
    "print(f\"R-squared (Lasso): {r2_nl1}\")\n",
    "\n",
    "# Test model for L2 (RIDGE)\n",
    "model_nl2 = PolynomialRegressionWithRegularization(degree=2, alpha=0.05, learning_rate=0.001, n_iterations=10000, regularization=\"l2\")\n",
    "model_nl2.fit(X_train, y_train)\n",
    "y_pred_nl2 = model_nl2.predict(X_test)\n",
    "\n",
    "# Evaluate L2 model\n",
    "r2_nl2 = r2_score(y_test, y_pred_nl2)\n",
    "print(f\"R-squared (Ridge): {r2_nl2}\")\n",
    "\n",
    "# Convert predictions to pandas Series with y_test's original index\n",
    "y_pred_nl1 = pd.Series(y_pred_nl1, index=y_test.index)\n",
    "y_pred_nl2 = pd.Series(y_pred_nl2, index=y_test.index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6?: Revenue Calculation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert y_pred_lasso to df\n",
    "y_pred_lasso_df = pd.DataFrame(y_pred_lasso, columns=['y_pred_lasso'])\n",
    "# Get ts for test\n",
    "ts_test = ts[split_index:]\n",
    "\n",
    "# Merge them on index\n",
    "pred = pd.merge(ts_test, y_pred_lasso_df, left_index=True, right_index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert y_test_pred_gd to df\n",
    "y_test_pred_gd_df = pd.DataFrame(y_test_pred_gd, columns=['y_pred_gd'])\n",
    "# Convert y_pred_poly to df\n",
    "y_pred_poly_df = pd.DataFrame(y_pred_poly, columns=['y_pred_poly'])\n",
    "# Convert y_pred_weighted to df\n",
    "y_pred_weighted_df = pd.DataFrame(y_pred_weighted, columns=['y_pred_weighted'])\n",
    "# Convert y_pred_l1 to df\n",
    "y_pred_l1_df = pd.DataFrame(y_pred_l1, columns=['y_pred_l1'])\n",
    "# Convert y_pred_nl1 to df\n",
    "y_pred_nl1_df = pd.DataFrame(y_pred_nl1, columns=['y_pred_nl1'])\n",
    "# Convert y_pred_l2 to df\n",
    "y_pred_l2_df = pd.DataFrame(y_pred_l2, columns=['y_pred_l2'])\n",
    "# Convert y_pred_nl2 to df\n",
    "y_pred_nl2_df = pd.DataFrame(y_pred_nl2, columns=['y_pred_nl2'])\n",
    "# Get ts for test\n",
    "ts_test = ts[split_index:]\n",
    "\n",
    "# Merge them on index\n",
    "preds = pd.merge(ts_test, y_test_pred_gd_df, left_index=True, right_index=True)\n",
    "preds = pd.merge(preds, y_pred_poly_df, left_index=True, right_index=True)\n",
    "preds = pd.merge(preds, y_pred_weighted_df, left_index=True, right_index=True)\n",
    "preds = pd.merge(preds, y_pred_l1_df, left_index=True, right_index=True)\n",
    "preds = pd.merge(preds, y_pred_nl1_df, left_index=True, right_index=True)\n",
    "preds = pd.merge(preds, y_pred_l2_df, left_index=True, right_index=True)\n",
    "preds = pd.merge(preds, y_pred_nl2_df, left_index=True, right_index=True)\n",
    "preds.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "nordpool.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "energinet.head()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
