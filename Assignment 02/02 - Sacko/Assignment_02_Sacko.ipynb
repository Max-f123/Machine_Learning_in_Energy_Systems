{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T10:42:22.417815Z",
     "start_time": "2024-11-16T10:42:22.135208Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sample data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T10:42:24.737718Z",
     "start_time": "2024-11-16T10:42:22.417815Z"
    }
   },
   "source": [
    "# Load and wind capacity ranges (example data)\n",
    "load_ranges = [56, 112, 120]  # Load range values (L1, L2, L3)\n",
    "wind_capacity_ranges = [10, 30]  # Wind production capacity (W1, W2)\n",
    "num_samples = 10  # Number of samples\n",
    "\n",
    "# Function to generate a sample for 24 hours with 7-column structure\n",
    "def generate_samples(num_samples, num_hours=24):\n",
    "    data = []\n",
    "    for sample_num in range(1, num_samples + 1):\n",
    "        for hour in range(0, num_hours):\n",
    "            load_sample = [np.random.choice(load_ranges) for _ in range(3)]  # For L1, L2, L3\n",
    "            wind_sample = [np.random.choice(wind_capacity_ranges) for _ in range(2)]  # For W1, W2\n",
    "            row = [sample_num, hour] + load_sample + wind_sample  # [Sample Number, Hour, L1, L2, L3, W1, W2]\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "# Generate data for 1000 samples\n",
    "samples_data = generate_samples(num_samples=1000)\n",
    "\n",
    "# Create column names for the DataFrame\n",
    "columns = [\"Sample_Number\", \"Hour\", \"Load_L1\", \"Load_L2\", \"Load_L3\", \"Wind_W1\", \"Wind_W2\"]\n",
    "\n",
    "# Create the DataFrame\n",
    "samples_df_new_structure = pd.DataFrame(samples_data, columns=columns)\n",
    "\n",
    "# Save to CSV\n",
    "samples_df_new_structure.to_csv(\"samples2.csv\", index=False)\n",
    "\n",
    "# Display the updated DataFrame structure\n",
    "samples_df_new_structure.head(24)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Sample_Number  Hour  Load_L1  Load_L2  Load_L3  Wind_W1  Wind_W2\n",
       "0               1     0      112      120      120       30       10\n",
       "1               1     1       56      120      120       30       10\n",
       "2               1     2      120       56      120       10       10\n",
       "3               1     3      112      120      120       10       10\n",
       "4               1     4       56      112      112       30       30\n",
       "5               1     5       56       56      120       10       10\n",
       "6               1     6       56       56      112       30       10\n",
       "7               1     7      120      112      120       10       10\n",
       "8               1     8      112      112       56       30       10\n",
       "9               1     9       56      120       56       10       30\n",
       "10              1    10       56       56      120       10       30\n",
       "11              1    11      120      112      112       30       30\n",
       "12              1    12      112      112       56       30       10\n",
       "13              1    13      120       56      112       10       30\n",
       "14              1    14      112      112      112       10       10\n",
       "15              1    15      120      120       56       30       30\n",
       "16              1    16       56      120       56       30       10\n",
       "17              1    17      112       56       56       10       30\n",
       "18              1    18      120      112      120       10       10\n",
       "19              1    19      112      120       56       10       30\n",
       "20              1    20      120      120       56       10       30\n",
       "21              1    21       56      112      120       30       10\n",
       "22              1    22      112       56      120       30       30\n",
       "23              1    23      120      120      112       10       10"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_Number</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Load_L1</th>\n",
       "      <th>Load_L2</th>\n",
       "      <th>Load_L3</th>\n",
       "      <th>Wind_W1</th>\n",
       "      <th>Wind_W2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>112</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>120</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>56</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>112</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>56</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>112</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>120</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>56</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>112</td>\n",
       "      <td>56</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>112</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1] Build the optimisation model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T10:42:27.546453Z",
     "start_time": "2024-11-16T10:42:24.740726Z"
    }
   },
   "source": [
    "# Load the data from the data folder\n",
    "wind_forecast = pd.read_csv('Data/1.Wind forecast profile.csv', delimiter=';')\n",
    "load = pd.read_csv('Data/1.Load profile.csv', delimiter=';')\n",
    "bus = pd.read_csv('Data/B (power transfer factor of each bus to each line).csv', delimiter=';')\n",
    "max_prod = pd.read_csv('Data/Maximum production of generating units.csv', delimiter=';')\n",
    "min_prod = pd.read_csv('Data/Minimum production of generating units.csv', delimiter=';')\n",
    "min_down_time = pd.read_csv('Data/Minimum down time of generating units.csv', delimiter=';')\n",
    "min_up_time = pd.read_csv('Data/Minimum up time of generating units.csv', delimiter=';')\n",
    "prod_cost = pd.read_csv('Data/Production cost of generating units.csv', delimiter=';')\n",
    "ramp_rate = pd.read_csv('Data/Ramping rate of generating units.csv', delimiter=';')\n",
    "start_up_cost = pd.read_csv('Data/Start-up cost of generating units.csv', delimiter=';')\n",
    "transmission_cap = pd.read_csv('Data/Transmission capacity of lines.csv', delimiter=';')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# wind_forecast = pd.read_csv('Data/1.Wind forecast profile.csv', delimiter=';')\n",
    "# load = pd.read_csv('Data/1.Load profile.csv', delimiter=';')\n",
    "samples = pd.read_csv('samples.csv', delimiter=',')\n",
    "\n",
    "# Now proceed to combine columns if the column names are correct\n",
    "load_tot = samples[['Hour','Load_L1', 'Load_L2', 'Load_L3']]\n",
    "wind_forecast_tot = samples[['Hour','Wind_W1', 'Wind_W2']]\n",
    "\n",
    "# print(load)\n",
    "# print(wind_forecast)\n",
    "print(load_tot)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/1.Wind forecast profile.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Load the data from the data folder\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m wind_forecast \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mData/1.Wind forecast profile.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m;\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m load \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mData/1.Load profile.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, delimiter\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m;\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m bus \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mData/B (power transfer factor of each bus to each line).csv\u001B[39m\u001B[38;5;124m'\u001B[39m, delimiter\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m;\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[0;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    330\u001B[0m     )\n\u001B[1;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    947\u001B[0m )\n\u001B[0;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    602\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    604\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 605\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1733\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1734\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1735\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1737\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1738\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1739\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1740\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1741\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1742\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1743\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    851\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    852\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    853\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    855\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 856\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    858\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    859\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    865\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'Data/1.Wind forecast profile.csv'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Nodes = ['Node 1', 'Node 2', 'Node 3', 'Node 4', 'Node 5', 'Node 6']\n",
    "Generator = ['G1', 'G2', 'G3']\n",
    "Generator_node = {'Node 1': 'G1', 'Node 2': 'G2', 'Node 6': 'G3'}\n",
    "Load = ['L1', 'L2', 'L3']\n",
    "Load_node = {'Node 4': 'L1', 'Node 5': 'L2', 'Node 6': 'L3'}\n",
    "Wind = ['W1', 'W2']\n",
    "Wind_node = {'Node 4': 'W1', 'Node 5': 'W2'}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create matrix with the nodes as columns and the generators, loads and winds as rows, with 1 if connected to the node\n",
    "Gen_n = np.zeros((len(Generator), len(Nodes)))\n",
    "Load_n = np.zeros((len(Load), len(Nodes)))\n",
    "Wind_n = np.zeros((len(Wind), len(Nodes)))\n",
    "\n",
    "# Populate the matrix\n",
    "for i, g in enumerate(Generator):  # Iterate over generators\n",
    "    for j, node in enumerate(Nodes):  # Iterate over nodes\n",
    "        if Generator_node.get(node) == g:  # Check if generator is connected to the node\n",
    "            Gen_n[i, j] = 1\n",
    "\n",
    "for i, l in enumerate(Load):  # Iterate over loads\n",
    "    for j, node in enumerate(Nodes):  # Iterate over nodes\n",
    "        if Load_node.get(node) == l:  # Check if load is connected to the node\n",
    "            Load_n[i, j] = 1\n",
    "\n",
    "for i, w in enumerate(Wind):  # Iterate over winds\n",
    "    for j, node in enumerate(Nodes):  # Iterate over nodes\n",
    "        if Wind_node.get(node) == w:  # Check if wind is connected to the node\n",
    "            Wind_n[i, j] = 1\n",
    "            \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define the input data class\n",
    "class InputData:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        wind_forecast: pd.DataFrame, \n",
    "        bus: pd.DataFrame,\n",
    "        load: pd.DataFrame,\n",
    "        max_prod: pd.DataFrame,\n",
    "        min_prod: pd.DataFrame,\n",
    "        min_down_time: pd.DataFrame,\n",
    "        min_up_time: pd.DataFrame,\n",
    "        prod_cost: pd.DataFrame,\n",
    "        ramp_rate: pd.DataFrame,\n",
    "        start_up_cost: pd.DataFrame,\n",
    "        transmission_cap: pd.DataFrame\n",
    "    ):\n",
    "        self.time = wind_forecast['Hour']  #maybe define it with lenght of wind_production\n",
    "        self.wind_forecast = wind_forecast\n",
    "        self.bus = bus\n",
    "        self.load = load\n",
    "        self.max_prod = max_prod\n",
    "        self.min_prod = min_prod\n",
    "        self.min_down_time = min_down_time\n",
    "        self.min_up_time = min_up_time\n",
    "        self.prod_cost = prod_cost\n",
    "        self.ramp_rate = ramp_rate\n",
    "        self.start_up_cost = start_up_cost\n",
    "        self.transmission_cap = transmission_cap\n",
    "        self.M = 1000000  # Penalty for having flexible demand\n",
    "        self.Gen_n = Gen_n  # Matrix mapping generators to nodes\n",
    "        self.Load_n = Load_n # Matrix mapping loads to nodes\n",
    "        self.Wind_n = Wind_n # Matrix mapping wind to nodes\n",
    "        \n",
    "        \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class Expando(object):\n",
    "    '''\n",
    "        A small class which can have attributes set\n",
    "    '''\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define the optimization model class\n",
    "\n",
    "class EconomicDispatch():\n",
    "        \n",
    "        def __init__(self, input_data: InputData):\n",
    "            self.data = input_data \n",
    "            self.variables = Expando()\n",
    "            self.constraints = Expando() \n",
    "            self.results = Expando() \n",
    "            self._build_model() \n",
    "            \n",
    "        def _build_variables(self):\n",
    "            # one binary variable for the status of each generator\n",
    "            self.variables.status = {\n",
    "                (i, t): self.model.addVar(vtype=GRB.BINARY, \n",
    "                                            name='status_G{}_{}'.format(i, t)) \n",
    "                                            for i in range(1, len(self.data.max_prod)+1) \n",
    "                                            for t in self.data.time}\n",
    "            \n",
    "            # one variable for each generator for each time of the day\n",
    "            self.variables.prod_gen = {\n",
    "                 (i, t): self.model.addVar(lb=0, ub=self.data.max_prod.iloc[i-1, 0], \n",
    "                                           name='generation_G{}_{}'.format(i, t)) \n",
    "                                           for i in range(1, len(self.data.max_prod)+1) \n",
    "                                           for t in self.data.time}\n",
    "            \n",
    "            # one variable for each wind generator for each time of the day\n",
    "            self.variables.prod_wind = {\n",
    "                 (i, t): self.model.addVar(lb=0, ub=self.data.wind_forecast.iloc[t, i], \n",
    "                                            name='wind_generation_W{}_{}'.format(i, t)) \n",
    "                                            for i in range(1, len(self.data.wind_forecast.iloc[0, :])) \n",
    "                                            for t in self.data.time}\n",
    "            \n",
    "            # one variable for each start-up cost for each generator\n",
    "            self.variables.start_up_cost = {\n",
    "                 (i, t): self.model.addVar(lb=0, \n",
    "                                            name='start_up_cost_G{}_{}'.format(i, t)) \n",
    "                                            for i in range(1, len(self.data.max_prod)+1) \n",
    "                                            for t in self.data.time}\n",
    "            \n",
    "            # add two slack variables to always make the model feasible, allowing the demand to be flexible\n",
    "            self.variables.epsilon = {\n",
    "                 (n, t): self.model.addVar(lb=0, \n",
    "                                           name='epsilon_Bus{}_{}'.format(n, t)) \n",
    "                                           for n in range(1, len(self.data.bus.iloc[0,:])+1) \n",
    "                                           for t in self.data.time}\n",
    "            self.variables.delta = {\n",
    "                 (n, t): self.model.addVar(lb=0, \n",
    "                                           name='delta_Bus{}_{}'.format(n, t))\n",
    "                                           for n in range(1, len(self.data.bus.iloc[0,:])+1)\n",
    "                                           for t in self.data.time}\n",
    "            \n",
    "            \n",
    "        def _build_constraints(self):\n",
    "            # Minimum capacity of the generator\n",
    "            self.constraints.min_capacity = {\n",
    "                (i, t): self.model.addConstr(\n",
    "                    self.variables.prod_gen[i, t] >= self.data.min_prod.iloc[i-1, 0] * self.variables.status[i, t]\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) for t in self.data.time}\n",
    "            # Maximum capacity of the generator\n",
    "            self.constraints.max_capacity = {\n",
    "                (i, t): self.model.addConstr(\n",
    "                    self.variables.prod_gen[i, t] <= self.data.max_prod.iloc[i-1, 0] * self.variables.status[i, t]\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) for t in self.data.time}\n",
    "\n",
    "            # Power balance constraint\n",
    "            self.constraints.power_balance = {\n",
    "                t: self.model.addConstr(\n",
    "                    gp.quicksum(self.variables.prod_gen[i, t] for i in range(1, len(self.data.max_prod)+1)) + \n",
    "                    gp.quicksum(self.variables.prod_wind[i, t] for i in range(1, len(self.data.wind_forecast.iloc[0, :]))) == \n",
    "                    gp.quicksum(self.data.load.iloc[t, i] * Load_n[i-1, n-1] + self.variables.epsilon[n, t] - self.variables.delta[n, t] \n",
    "                        for i in range(1, len(self.data.load.iloc[0, :]))\n",
    "                        for n in range(1, len(self.data.bus.iloc[0,:])+1))\n",
    "                ) for t in self.data.time}\n",
    "\n",
    "            # Transmission capacity constraint\n",
    "            self.constraints.transmission_capacity_up = {\n",
    "                    (l, t): self.model.addConstr(\n",
    "                        gp.quicksum(self.data.bus.iloc[l-1, n-1] *\n",
    "                                (self.variables.prod_gen[i, t] * Gen_n[i-1, n-1] +\n",
    "                                self.variables.prod_wind[i, t] * Wind_n[i-1, n-1] -\n",
    "                                self.variables.epsilon[n, t] +\n",
    "                                self.variables.delta[n, t]) for n in range(1, len(self.data.bus.iloc[0,:])+1)) <=\n",
    "                        self.data.transmission_cap.iloc[l-1, 0]\n",
    "                    ) for l in range(1, len(self.data.transmission_cap)+1)\n",
    "                    for t in self.data.time}\n",
    "            self.constraints.transmission_capacity_down = {\n",
    "                    (l, t): self.model.addConstr(\n",
    "                        gp.quicksum(self.data.bus.iloc[l-1, n-1] *\n",
    "                                (self.variables.prod_gen[i, t] * Gen_n[i-1, n-1] +\n",
    "                                self.variables.prod_wind[i, t] * Wind_n[i-1, n-1] -\n",
    "                                self.variables.epsilon[n, t] +\n",
    "                                self.variables.delta[n, t]) for n in range(1, len(self.data.bus.iloc[0,:])+1)) >=\n",
    "                        -self.data.transmission_cap.iloc[l-1, 0]\n",
    "                    ) for l in range(1, len(self.data.transmission_cap)+1)\n",
    "                    for t in self.data.time}\n",
    "                                     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #Start-up costs constraint\n",
    "            self.constraints.start_up_cost = {\n",
    "                (i, t): self.model.addConstr(\n",
    "                    self.variables.start_up_cost[i, t] >= self.data.start_up_cost.iloc[i-1, 0] * (self.variables.status[i, t] - self.variables.status[i, t-1])\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) for t in self.data.time if t > 0}\n",
    "            self.constraints.start_up_cost_0 = {\n",
    "                i: self.model.addConstr(\n",
    "                    self.variables.start_up_cost[i, 0] >= self.data.start_up_cost.iloc[i-1, 0] * self.variables.status[i, 0]\n",
    "                ) for i in range(1, len(self.data.max_prod)+1)}\n",
    "            \n",
    "            # Ramping constraint\n",
    "            self.constraints.ramping_up = {\n",
    "                (i, t): self.model.addConstr(\n",
    "                    self.variables.prod_gen[i, t] - self.variables.prod_gen[i, t-1] <= self.data.ramp_rate.iloc[i-1, 0]\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) for t in self.data.time if t > 0}\n",
    "            self.constraints.ramping_down = {\n",
    "                (i, t): self.model.addConstr(\n",
    "                    self.variables.prod_gen[i, t-1] - self.variables.prod_gen[i, t] <= self.data.ramp_rate.iloc[i-1, 0]\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) for t in self.data.time if t > 0}\n",
    "            \n",
    "            # Minimum up time constraint\n",
    "            self.constraints.min_up_time = {\n",
    "                (i, t, to): self.model.addConstr(\n",
    "                    -self.variables.status[i, t - 1] + self.variables.status[i, t] - self.variables.status[i, to] <= 0\n",
    "                ) for i in range(1, len(self.data.max_prod) + 1) \n",
    "                for t in self.data.time \n",
    "                for to in range(t, min(t + self.data.min_up_time.iloc[i-1, 0], 24)) if t > 0  # Ensure to does not exceed 23\n",
    "            }\n",
    "\n",
    "\n",
    "            \n",
    "            # Minimum down time constraint\n",
    "            self.constraints.min_down_time = {\n",
    "                (i, t, to): self.model.addConstr(\n",
    "                    self.variables.status[i, t - 1] - self.variables.status[i, t] + self.variables.status[i, to] <= 1\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) \n",
    "                for t in self.data.time \n",
    "                for to in range(t, min(t + self.data.min_down_time.iloc[i-1, 0], 24)) if t > 0}\n",
    "            \n",
    "\n",
    "\n",
    "        def _build_objective(self):\n",
    "            # Objective function\n",
    "            self.model.setObjective(\n",
    "                gp.quicksum(self.data.prod_cost.iloc[i-1, 0]*self.variables.prod_gen[i, t] for i in range(1, len(self.data.max_prod)+1) for t in self.data.time) +\n",
    "                gp.quicksum(self.variables.start_up_cost[i, t] for i in range(1, len(self.data.max_prod)+1) for t in self.data.time) +\n",
    "                self.data.M * (gp.quicksum(self.variables.epsilon[n, t] + self.variables.delta[n, t] for n in range(1, len(self.data.bus.iloc[0,:])+1) for t in self.data.time))\n",
    "            )\n",
    "\n",
    "        def _build_model(self):\n",
    "            self.model = gp.Model('EconomicDispatch')\n",
    "            self._build_variables()\n",
    "            self._build_constraints()\n",
    "            self._build_objective()\n",
    "            self.model.update()\n",
    "\n",
    "        def optimize(self):\n",
    "            self.model.optimize()\n",
    "            self._extract_results()\n",
    "\n",
    "        def _extract_results(self):\n",
    "            self.results.production = pd.DataFrame({\n",
    "                #'time': [t for t in self.data.time],\n",
    "                #'status G1': [self.variables.status[1, t].x for t in self.data.time],\n",
    "                #'status G2': [self.variables.status[2, t].x for t in self.data.time],\n",
    "                #'status G3': [self.variables.status[3, t].x for t in self.data.time],\n",
    "                #'start_up_cost 1': [self.variables.start_up_cost[1, t].x for t in self.data.time],\n",
    "                #'start_up_cost 2': [self.variables.start_up_cost[2, t].x for t in self.data.time],\n",
    "                #'start_up_cost 3': [self.variables.start_up_cost[3, t].x for t in self.data.time],\n",
    "                'generation 1': [self.variables.prod_gen[1, t].x for t in self.data.time],\n",
    "                'generation 2': [self.variables.prod_gen[2, t].x for t in self.data.time],\n",
    "                'generation 3': [self.variables.prod_gen[3, t].x for t in self.data.time],\n",
    "                'wind generation 1': [self.variables.prod_wind[1, t].x for t in self.data.time],\n",
    "                'wind generation 2': [self.variables.prod_wind[2, t].x for t in self.data.time],\n",
    "                'load 1': [self.data.load.iloc[t, 1] for t in self.data.time],\n",
    "                'load 2': [self.data.load.iloc[t, 2] for t in self.data.time],\n",
    "                'load 3': [self.data.load.iloc[t, 3] for t in self.data.time],\n",
    "                'epsilon 1': [self.variables.epsilon[1, t].x for t in self.data.time],\n",
    "                'delta 1': [self.variables.delta[1, t].x for t in self.data.time],\n",
    "                'epsilon 2': [self.variables.epsilon[2, t].x for t in self.data.time],\n",
    "                'delta 2': [self.variables.delta[2, t].x for t in self.data.time],\n",
    "                'epsilon 3': [self.variables.epsilon[3, t].x for t in self.data.time],\n",
    "                'delta 3': [self.variables.delta[3, t].x for t in self.data.time],\n",
    "                'epsilon 4': [self.variables.epsilon[4, t].x for t in self.data.time],\n",
    "                'delta 4': [self.variables.delta[4, t].x for t in self.data.time],\n",
    "                'epsilon 5': [self.variables.epsilon[5, t].x for t in self.data.time],\n",
    "                'delta 5': [self.variables.delta[5, t].x for t in self.data.time],\n",
    "                'epsilon 6': [self.variables.epsilon[6, t].x for t in self.data.time],\n",
    "                'delta 6': [self.variables.delta[6, t].x for t in self.data.time]\n",
    "            })\n",
    "            self.results.unit_commitment = pd.DataFrame({\n",
    "                'time': [t for t in self.data.time],\n",
    "                'G1': [self.variables.status[1, t].x for t in self.data.time],\n",
    "                'G2': [self.variables.status[2, t].x for t in self.data.time],\n",
    "                'G3': [self.variables.status[3, t].x for t in self.data.time]\n",
    "            })\n",
    "            "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Run the model\n",
    "input_data = InputData(wind_forecast_tot, bus, load_tot, max_prod, min_prod, min_down_time, min_up_time, prod_cost, ramp_rate, start_up_cost, transmission_cap)\n",
    "model = EconomicDispatch(input_data)\n",
    "model.optimize()\n",
    "model.results.production\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.results.unit_commitment #to be used for the next steps"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data preparation  \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "unit_commitment_df = model.results.unit_commitment\n",
    "\n",
    "# Convert the float values to integers for the unit status columns (G1, G2, G3)\n",
    "unit_commitment_df[['G1', 'G2', 'G3']] = unit_commitment_df[['G1', 'G2', 'G3']].astype(int)\n",
    "\n",
    "# Define features and labels\n",
    "# Assuming that 'time' can be used as an index or feature\n",
    "features = unit_commitment_df[['time']]  # Add other features as needed\n",
    "labels = unit_commitment_df[['G1', 'G2', 'G3']]  # Binary labels for each generator\n",
    "\n",
    "# Split the dataset into training (60%), validation (20%), and testing (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the split sizes\n",
    "print(\"Training set size:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set size:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Save the training, validation, and testing sets as CSV files if needed\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "X_val.to_csv('X_val.csv', index=False)\n",
    "y_val.to_csv('y_val.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Classification:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check label distribution for each unit\n",
    "for unit in ['G1', 'G2', 'G3']:\n",
    "    print(f\"Label distribution for {unit}:\")\n",
    "    print(y_train[unit].value_counts())\n",
    "    print()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Comparison of Classifier Performance\n",
    "\n",
    "## Metrics for Evaluation:\n",
    "\n",
    "### 1. **Accuracy**:\n",
    "- **Definition**: The proportion of correct predictions out of the total number of samples.\n",
    "- **Use Case**: Useful for understanding the overall correctness of the model's predictions.\n",
    "- **Formula**: \n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "### 2. **Precision**:\n",
    "- **Definition**: The proportion of true positive predictions among all positive predictions.\n",
    "- **Use Case**: Important for problems where minimizing false positives is critical.\n",
    "- **Formula**:\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "### 3. **Recall (Sensitivity/True Positive Rate)**:\n",
    "- **Definition**: The proportion of actual positive cases that were correctly identified.\n",
    "- **Use Case**: Useful when the focus is on minimizing false negatives.\n",
    "- **Formula**:\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "### 4. **F1 Score**:\n",
    "- **Definition**: The harmonic mean of precision and recall, balancing the trade-off between precision and recall.\n",
    "- **Use Case**: A good metric when a balance between precision and recall is needed, especially in cases of imbalanced datasets.\n",
    "- **Formula**:\n",
    "$$\n",
    "\\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "### 5. **Confusion Matrix**:\n",
    "- **Definition**: A table showing the number of true positive, true negative, false positive, and false negative predictions.\n",
    "- **Use Case**: Provides a complete view of how the model performs across different classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Dictionary to store trained models for each unit\n",
    "trained_models = {}\n",
    "\n",
    "# Function to train and evaluate classifiers\n",
    "def train_and_evaluate(X_train, X_val, y_train, y_val, unit_name):\n",
    "    # Check if the unit has samples for both classes\n",
    "    if len(y_train[unit_name].unique()) < 2:\n",
    "        print(f\"Skipping training for {unit_name} as it only contains one class.\")\n",
    "        return\n",
    "\n",
    "    # Dictionary to store models for this unit\n",
    "    unit_models = {\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'SVM (RBF Kernel)': SVC(kernel='rbf')\n",
    "    }\n",
    "    results = {}\n",
    "\n",
    "    # Train and evaluate each model\n",
    "    for model_name, model in unit_models.items():\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train[unit_name])\n",
    "        \n",
    "        # Store the trained model\n",
    "        trained_models[(unit_name, model_name)] = model\n",
    "        \n",
    "        # Predict on validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        accuracy = accuracy_score(y_val[unit_name], y_pred)\n",
    "        precision = precision_score(y_val[unit_name], y_pred, zero_division=0)\n",
    "        recall = recall_score(y_val[unit_name], y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val[unit_name], y_pred, zero_division=0)\n",
    "        \n",
    "        # Store the results\n",
    "        results[model_name] = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{model_name} for {unit_name}:\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"Precision: {precision:.2f}\")\n",
    "        print(f\"Recall: {recall:.2f}\")\n",
    "        print(f\"F1 Score: {f1:.2f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Loop through each generating unit to train and evaluate models\n",
    "for unit in ['G1', 'G2', 'G3']:\n",
    "    print(f\"\\nTraining classifiers for {unit}:\")\n",
    "    train_and_evaluate(X_train, X_val, y_train, y_val, unit)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(trained_models)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Function to evaluate and summarize performance\n",
    "def evaluate_and_compare(X_test, y_test, trained_models, unit_name):\n",
    "    results_summary = []\n",
    "\n",
    "    for model_name, model in trained_models.items():\n",
    "        # Predict on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test[unit_name], y_pred)\n",
    "        precision = precision_score(y_test[unit_name], y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test[unit_name], y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test[unit_name], y_pred, zero_division=0)\n",
    "\n",
    "        # Append metrics to results summary\n",
    "        results_summary.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1\n",
    "        })\n",
    "\n",
    "        # Print classification report and confusion matrix\n",
    "        print(f\"\\nClassification Report for {model_name} - {unit_name}:\\n\")\n",
    "        print(classification_report(y_test[unit_name], y_pred, zero_division=0))\n",
    "        print(f\"Confusion Matrix for {model_name} - {unit_name}:\\n\")\n",
    "        print(confusion_matrix(y_test[unit_name], y_pred))\n",
    "        print()\n",
    "\n",
    "    # Create a DataFrame for summary\n",
    "    results_df = pd.DataFrame(results_summary)\n",
    "    print(f\"\\nPerformance Summary for {unit_name}:\\n\")\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Assuming `trained_models` is a dictionary containing trained models for each unit\n",
    "for unit in ['G1', 'G2', 'G3']:\n",
    "    print(f\"\\nEvaluating models for {unit}:\")\n",
    "    evaluate_and_compare(X_test, y_test, trained_models, unit)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot actual vs predicted values for each unit and model\n",
    "def plot_predictions(X_test, y_test, trained_models, unit_name):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "    fig.suptitle(f'Actual vs Predicted Values for {unit_name}', fontsize=16)\n",
    "\n",
    "    models = ['Logistic Regression', 'SVM (RBF Kernel)']\n",
    "    \n",
    "    for i, model_name in enumerate(models):\n",
    "        model = trained_models.get((unit_name, model_name))\n",
    "        if model:\n",
    "            y_pred = model.predict(X_test)\n",
    "            axes[i].plot(y_test[unit_name].values, label='Actual', marker='o', linestyle='-', alpha=0.6)\n",
    "            axes[i].plot(y_pred, label='Predicted', marker='x', linestyle='--', alpha=0.6)\n",
    "            axes[i].set_title(model_name)\n",
    "            axes[i].set_xlabel('Sample Index')\n",
    "            axes[i].set_ylabel('Status (0/1)')\n",
    "            axes[i].legend()\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, 'Model not available', horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Plot for each unit\n",
    "for unit in ['G3']:\n",
    "    plot_predictions(X_test, y_test, trained_models, unit)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
