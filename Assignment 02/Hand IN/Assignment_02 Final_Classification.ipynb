{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:32:30.222994Z",
     "start_time": "2024-11-22T21:32:30.205986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, matthews_corrcoef, balanced_accuracy_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data. If existing solution for optimization problem shall be used, use the \"results1000\" code. Otherwise use the \n",
    "results = pd.read_csv('results1000.csv', delimiter=',') \n",
    "results_UC = pd.read_csv('unit_comitment1000.csv', delimiter=',')\n",
    "\n",
    "# results = pd.read_csv('Data/resultsopti.csv', delimiter=',') \n",
    "# results_UC = pd.read_csv('Data/unit_comitmentopti.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 03: Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original feature space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:33:11.234423Z",
     "start_time": "2024-11-22T21:33:11.064904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1    1.000000\n",
      "G2    0.696333\n",
      "G3    0.965833\n",
      "dtype: float64\n",
      "Units to classify: Index(['G2', 'G3'], dtype='object')\n",
      "--------------------------------------------------\n",
      "Shapes:  (16800, 5) (3600, 5) (16800, 2) (3600, 2) (3600, 5) (3600, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Check if units are always ON or OFF\n",
    "targets = results_UC[[\"G1\",\"G2\",\"G3\"]]\n",
    "print(targets.mean())\n",
    "\n",
    "# Filter out units that are always ON or OFF\n",
    "units_to_classify = targets.columns[(targets.mean() > 0) & (targets.mean() < 1)]\n",
    "print(f\"Units to classify: {units_to_classify}\")\n",
    "print(\"-\"*50)\n",
    "targets = targets[units_to_classify]\n",
    "features = results[['wind generation 1', 'wind generation 2', 'load 1', 'load 2', 'load 3']]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features = pd.DataFrame(scaler.fit_transform(features), columns=results[['wind generation 1', 'wind generation 2', 'load 1', 'load 2', 'load 3']].columns)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(features, targets, test_size=0.3, random_state=42, shuffle=False)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, shuffle=False)\n",
    "\n",
    "# Shape\n",
    "print(\"Shapes: \", X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large feature space (incl. lagged features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:33:11.266421Z",
     "start_time": "2024-11-22T21:33:11.238414Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lagging Function\n",
    "def lag_features(features, lags, targets=None, lag_targets=False):\n",
    "    \"\"\"\n",
    "    Creates lagged versions of the features for a given number of lags.\n",
    "    Optionally adds lagged versions of the targets as well.\n",
    "    Parameters:\n",
    "    - features (pd.DataFrame): The input feature DataFrame.\n",
    "    - lags (int): Number of lagged steps to create.\n",
    "    - targets (pd.DataFrame, optional): The target DataFrame to lag.\n",
    "    - lag_targets (bool): Whether to include lagged versions of targets.\n",
    "    \"\"\"\n",
    "    lagged_features = features.copy()\n",
    "    for lag in range(1, lags + 1):\n",
    "        lagged = features.shift(lag)\n",
    "        lagged.columns = [f\"{col}_lag{lag}\" for col in features.columns]\n",
    "        lagged_features = pd.concat([lagged_features, lagged], axis=1)\n",
    "\n",
    "    # Add lagged targets if specified\n",
    "    if lag_targets and targets is not None:\n",
    "        for lag in range(1, lags + 1):\n",
    "            lagged = targets.shift(lag)\n",
    "            lagged.columns = [f\"{col}_lag{lag}\" for col in targets.columns]\n",
    "            lagged_features = pd.concat([lagged_features, lagged], axis=1)\n",
    "    \n",
    "    # Drop rows with NaN values from lagging\n",
    "    return lagged_features.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:33:11.297414Z",
     "start_time": "2024-11-22T21:33:11.271420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multi-Class Target Transformation (nested)\n",
    "def transform_targets_to_multiclass(targets_df):\n",
    "    \"\"\"\n",
    "    Transforms binary targets (G2, G3) into multi-class categories.\n",
    "    \"\"\"\n",
    "    def map_targets(row):\n",
    "        if row['G2'] == 1 and row['G3'] == 1:\n",
    "            return 'A'\n",
    "        elif row['G2'] == 0 and row['G3'] == 1:\n",
    "            return 'B'\n",
    "        elif row['G2'] == 1 and row['G3'] == 0:\n",
    "            return 'C'\n",
    "        elif row['G2'] == 0 and row['G3'] == 0:\n",
    "            return 'D'\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected row values: G2={}, G3={}\".format(row['G2'], row['G3'])) # Catch unexpected values\n",
    "\n",
    "    # Copy targets\n",
    "    targets_MC = targets_df.copy()    \n",
    "    # Apply transformation\n",
    "    targets_MC['category'] = targets_df.apply(map_targets, axis=1)\n",
    "    # Drop original columns\n",
    "    targets_MC = targets_MC.drop(columns=['G2', 'G3'])\n",
    "    # Convert to categorical codes (0, 1, 2, 3)\n",
    "    targets_MC['category'] = pd.Categorical(targets_MC['category']).codes\n",
    "    return targets_MC[['category']]  # Return only the transformed category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:33:11.328945Z",
     "start_time": "2024-11-22T21:33:11.304409Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reverse Mapping\n",
    "def reverse_map_categories(categories, add_g1=True):\n",
    "    \"\"\"\n",
    "    Reverse map from multi-class categories to binary G1, G2, G3, ensuring column order.\n",
    "    \"\"\"\n",
    "    reverse_mapping = {\n",
    "        0: (1, 1),  # A\n",
    "        1: (0, 1),  # B\n",
    "        2: (1, 0),  # C\n",
    "        3: (0, 0),  # D\n",
    "    }\n",
    "\n",
    "    if isinstance(categories, (pd.Series, pd.DataFrame)):\n",
    "        mapped = categories.map(reverse_mapping)\n",
    "        result = pd.DataFrame(mapped.tolist(), columns=['G2', 'G3'])\n",
    "        if add_g1:\n",
    "            result.insert(0, 'G1', 1)  # Ensure G1 is the first column\n",
    "        return result[['G1', 'G2', 'G3']] if add_g1 else result[['G2', 'G3']]\n",
    "\n",
    "    result = reverse_mapping.get(categories, (None, None))\n",
    "    return (1, *result) if add_g1 else result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:33:11.360952Z",
     "start_time": "2024-11-22T21:33:11.333953Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine Lagging and Multi-Class Targets\n",
    "def prepare_data(features, targets, lags, lag_targets=False):\n",
    "    \"\"\"\n",
    "    Combines feature lagging and multi-class target transformation.\n",
    "    \"\"\"\n",
    "    # Lag the features\n",
    "    lagged_features = lag_features(features, lags, targets, lag_targets=lag_targets)\n",
    "\n",
    "    # Add hours to lagged features\n",
    "    lagged_features['Hour'] = features.index[lags:]\n",
    "\n",
    "    # Cyclic Scaling of Hour\n",
    "    lagged_features['Hour_sin'] = np.sin(2 * np.pi * lagged_features['Hour'] / 24)\n",
    "    lagged_features['Hour_cos'] = np.cos(2 * np.pi * lagged_features['Hour'] / 24)\n",
    "    lagged_features = lagged_features.drop(columns=['Hour'])\n",
    "    \n",
    "    # Align targets with lagged features\n",
    "    lagged_targets = targets.iloc[lags:].reset_index(drop=True)  # Drop first rows to match lagged features\n",
    "\n",
    "    # Transform targets to multi-class\n",
    "    multiclass_targets = transform_targets_to_multiclass(lagged_targets) #.reset_index(drop=True)\n",
    "\n",
    "    # Ensure alignment\n",
    "    assert lagged_features.shape[0] == multiclass_targets.shape[0], \"Mismatch in rows between features and targets\"\n",
    "    \n",
    "    return lagged_features, multiclass_targets #.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:33:11.391949Z",
     "start_time": "2024-11-22T21:33:11.363953Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add a function to evaluate and display performance metrics\n",
    "def evaluate_performance(y_true, y_pred, classes=['A', 'B', 'C', 'D'], title=\"Model\"):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a classification model using multiple metrics\n",
    "    and visualizes the confusion matrix.\n",
    "    \"\"\"\n",
    "    # Compute metrics\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    bal_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Performance Metrics for {title}:\")\n",
    "    print(f\"F1 Score (Weighted): {f1_weighted:.3f}\")\n",
    "    print(f\"F1 Score (Macro): {f1_macro:.3f}\")\n",
    "    print(f\"MCC: {mcc:.3f}\")\n",
    "    print(f\"Balanced Accuracy: {bal_accuracy:.3f}\") # kick?\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=classes,zero_division=0))\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:33:12.291973Z",
     "start_time": "2024-11-22T21:33:11.397966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Data:\n",
      "       Hour     L1     L2     L3        W1         W2\n",
      "16800     0  10.41  59.00  76.38  0.000000  15.036853\n",
      "16801     1   8.33  54.34  49.13  0.000000   1.800000\n",
      "16802     2   8.20  51.96  51.60  0.000000   1.760000\n",
      "16803     3   6.38  47.28  52.23  3.688951   0.000000\n",
      "16804     4   7.37  38.13  51.71  0.000000   0.000000\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation for Multi-Class Classification\n",
    "lagged_features, multiclass_targets = prepare_data(features, targets, lags=3)\n",
    "# Train-Test Split\n",
    "X_train_MC, X_temp_MC, y_train_MC, y_temp_MC = train_test_split(lagged_features, multiclass_targets['category'], test_size=0.3, random_state=42, shuffle=False)\n",
    "X_test_MC, X_val_MC, y_test_MC, y_val_MC = train_test_split(X_temp_MC, y_temp_MC, test_size=0.5, random_state=42, shuffle=False)\n",
    "\n",
    "# Reduce X_test_MC to original columns\n",
    "X_test_MC_reduced = X_test_MC[['wind generation 1', 'wind generation 2', 'load 1', 'load 2', 'load 3', 'Hour_sin', 'Hour_cos']].copy()\n",
    "# Reverse hour cyclic scaling\n",
    "X_test_MC_reduced['Hour'] = (np.arctan2(X_test_MC_reduced['Hour_sin'], X_test_MC_reduced['Hour_cos']) / (2 * np.pi) * 24).round().astype(int) % 24\n",
    "X_test_MC_reduced = X_test_MC_reduced.drop(columns=['Hour_sin', 'Hour_cos'])\n",
    "# Rescale features -> Select only the features to rescale \n",
    "features_to_rescale = ['wind generation 1', 'wind generation 2', 'load 1', 'load 2', 'load 3']\n",
    "non_scaled_features = ['Hour']\n",
    "hour_column = X_test_MC_reduced[non_scaled_features].copy()\n",
    "scaled_features = pd.DataFrame(\n",
    "    scaler.inverse_transform(X_test_MC_reduced[features_to_rescale]),\n",
    "    columns=features_to_rescale,\n",
    "    index=X_test_MC_reduced.index\n",
    ")\n",
    "X_test_MC_reduced = pd.concat([hour_column, scaled_features], axis=1)\n",
    "# Rename & reorder columns\n",
    "X_test_MC_reduced.columns = ['Hour', 'W1', 'W2', 'L1', 'L2', 'L3']\n",
    "X_test_MC_reduced = X_test_MC_reduced[['Hour', 'L1', 'L2', 'L3', 'W1', 'W2']]\n",
    "\n",
    "# Save to csv\n",
    "X_test_MC_reduced.to_csv('X_test_MC.csv', index=False)\n",
    "print(\"\\nTest Data:\")\n",
    "print(X_test_MC_reduced.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:33:56.758797Z",
     "start_time": "2024-11-22T21:33:12.294976Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train Logistic Regression\u001b[39;00m\n\u001b[0;32m      2\u001b[0m logreg_model \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mlogreg_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_MC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_MC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m y_pred_logreg \u001b[38;5;241m=\u001b[39m logreg_model\u001b[38;5;241m.\u001b[39mpredict(X_test_MC)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:1350\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1350\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1353\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:455\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    451\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (C \u001b[38;5;241m*\u001b[39m sw_sum)\n\u001b[0;32m    452\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    453\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    454\u001b[0m ]\n\u001b[1;32m--> 455\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    470\u001b[0m     solver,\n\u001b[0;32m    471\u001b[0m     opt_res,\n\u001b[0;32m    472\u001b[0m     max_iter,\n\u001b[0;32m    473\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    475\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\optimize\\_minimize.py:731\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    728\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    729\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 731\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    734\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    735\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\optimize\\_differentiable_functions.py:343\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[1;32m--> 343\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\optimize\\_differentiable_functions.py:294\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 294\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[0;32m    296\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\optimize\\_differentiable_functions.py:20\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     16\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\optimize\\_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\optimize\\_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 73\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_linear_loss.py:281\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n\u001b[1;32m--> 281\u001b[0m loss, grad_pointwise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m sw_sum \u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(sample_weight)\n\u001b[0;32m    288\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m sw_sum\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\_loss\\loss.py:202\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[1;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcloss\u001b[38;5;241m.\u001b[39mloss(\n\u001b[0;32m    194\u001b[0m         y_true\u001b[38;5;241m=\u001b[39my_true,\n\u001b[0;32m    195\u001b[0m         raw_prediction\u001b[38;5;241m=\u001b[39mraw_prediction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m    199\u001b[0m     )\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_out\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_gradient\u001b[39m(\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    204\u001b[0m     y_true,\n\u001b[0;32m    205\u001b[0m     raw_prediction,\n\u001b[0;32m    206\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    207\u001b[0m     loss_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    208\u001b[0m     gradient_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    209\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    210\u001b[0m ):\n\u001b[0;32m    211\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute loss and gradient w.r.t. raw_prediction for each input.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m        Element-wise gradients.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "logreg_model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "logreg_model.fit(X_train_MC, y_train_MC)\n",
    "y_pred_logreg = logreg_model.predict(X_test_MC)\n",
    "# Evaluate\n",
    "evaluate_performance(y_test_MC, y_pred_logreg, title=\"Logistic Regression\")\n",
    "\n",
    "# Train SVM with RBF kernel\n",
    "svm_rbf_model = SVC(kernel='rbf', random_state=42, class_weight='balanced', probability=True, C=10, gamma='scale')\n",
    "svm_rbf_model.fit(X_train_MC, y_train_MC)\n",
    "y_pred_svm_rbf = svm_rbf_model.predict(X_test_MC)\n",
    "# Evaluate\n",
    "evaluate_performance(y_test_MC, y_pred_svm_rbf, title=\"SVM with RBF Kernel\")\n",
    "\n",
    "# Reverse map\n",
    "y_pred_logreg = reverse_map_categories(pd.Series(y_pred_logreg))\n",
    "y_pred_reversed_svm_rbf = reverse_map_categories(pd.Series(y_pred_svm_rbf))\n",
    "y_test_reversed = reverse_map_categories(y_test_MC)\n",
    "\n",
    "# # Save Results to CSV\n",
    "#y_pred_reversed_svm_rbf.to_csv('Data/y_pred_svm.csv', index=False)\n",
    "#y_pred_logreg.to_csv('Data/y_pred_logreg.csv', index=False)\n",
    "#y_test_reversed.to_csv('Data/y_test.csv', index=False)\n",
    "\n",
    "# Print Results\n",
    "print(\"Predicted Values (Logistic Regression):\")\n",
    "print(y_pred_logreg.head())\n",
    "print(\"Predicted Values (SVM with RBF kernel):\")\n",
    "print(y_pred_reversed_svm_rbf.head())\n",
    "print(\"\\nTrue Values:\")\n",
    "print(y_test_reversed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection with GridSearch (Hyperparameter Tuning):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:39:50.233955Z",
     "start_time": "2024-11-22T21:33:56.760788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konst\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 1, 'solver': 'newton-cg'}\n",
      "Best cross-validated MCC: 0.912\n",
      "Performance Metrics for Tuned Logistic Regression:\n",
      "F1 Score (Weighted): 0.911\n",
      "F1 Score (Macro): 0.685\n",
      "MCC: 0.801\n",
      "Balanced Accuracy: 0.679\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.93      0.95      0.94      2472\n",
      "           B       0.86      0.82      0.84      1008\n",
      "           C       0.00      0.00      0.00         3\n",
      "           D       0.97      0.95      0.96       117\n",
      "\n",
      "    accuracy                           0.91      3600\n",
      "   macro avg       0.69      0.68      0.68      3600\n",
      "weighted avg       0.91      0.91      0.91      3600\n",
      "\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters for SVM: {'C': 10, 'degree': 2, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Best cross-validated MCC: 0.930\n",
      "Performance Metrics for Tuned SVM:\n",
      "F1 Score (Weighted): 0.930\n",
      "F1 Score (Macro): 0.694\n",
      "MCC: 0.843\n",
      "Balanced Accuracy: 0.685\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.94      0.96      0.95      2472\n",
      "           B       0.89      0.86      0.87      1008\n",
      "           C       0.00      0.00      0.00         3\n",
      "           D       0.98      0.92      0.95       117\n",
      "\n",
      "    accuracy                           0.93      3600\n",
      "   macro avg       0.70      0.69      0.69      3600\n",
      "weighted avg       0.93      0.93      0.93      3600\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Hyperparameter Tuning\n",
    "def tune_log_reg(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10],  # Regularization strength\n",
    "        'solver': ['lbfgs', 'newton-cg', 'saga'],  # Optimization algorithm\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        LogisticRegression(random_state=42, max_iter=1000, multi_class='multinomial', penalty='l2'),\n",
    "        param_grid,\n",
    "        scoring='f1_weighted',\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best parameters for Logistic Regression: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validated MCC: {grid_search.best_score_:.3f}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# SVM Hyperparameter Tuning\n",
    "def tune_svm(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],  # Regularization strength\n",
    "        'kernel': ['linear', 'poly', 'rbf'],  # Kernels to evaluate\n",
    "        'degree': [2, 3],  # Degree of polynomial kernel (ignored for others)\n",
    "        'gamma': ['scale', 'auto'],  # Kernel coefficient\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        SVC(random_state=42),\n",
    "        param_grid,\n",
    "        scoring='f1_weighted',\n",
    "        cv=5,  # 5-fold cross-validation\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best parameters for SVM: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validated MCC: {grid_search.best_score_:.3f}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Fine-tune Logistic Regression\n",
    "best_logistic_model = tune_log_reg(X_train_MC, y_train_MC)\n",
    "\n",
    "# Evaluate Logistic Regression with Best Parameters\n",
    "y_pred_logreg_tune = best_logistic_model.predict(X_test_MC)\n",
    "evaluate_performance(y_test_MC, y_pred_logreg_tune, title=\"Tuned Logistic Regression\")\n",
    "\n",
    "# Fine-tune SVM\n",
    "best_svm_model = tune_svm(X_train_MC, y_train_MC)\n",
    "\n",
    "# Evaluate SVM with Best Parameters\n",
    "y_pred_svm_tune = best_svm_model.predict(X_test_MC)\n",
    "evaluate_performance(y_test_MC, y_pred_svm_tune, title=\"Tuned SVM\")\n",
    "\n",
    "# Reverse map\n",
    "y_pred_logreg_tune = reverse_map_categories(pd.Series(y_pred_logreg_tune))\n",
    "y_pred_svm_tune = reverse_map_categories(pd.Series(y_pred_svm_tune))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:39:50.311230Z",
     "start_time": "2024-11-22T21:39:50.237490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Values (Tuned Logistic Regression):\n",
      "   Hour  G1  G2  G3\n",
      "0     0   1   0   1\n",
      "1     1   1   0   1\n",
      "2     2   1   0   1\n",
      "3     3   1   0   0\n",
      "4     4   1   0   0\n",
      "Predicted Values (Tuned SVM):\n",
      "   Hour  G1  G2  G3\n",
      "0     0   1   0   1\n",
      "1     1   1   0   1\n",
      "2     2   1   0   1\n",
      "3     3   1   0   0\n",
      "4     4   1   0   0\n",
      "\n",
      "True Values:\n",
      "      Hour  G1  G2  G3\n",
      "3595    19   1   1   1\n",
      "3596    20   1   1   1\n",
      "3597    21   1   1   1\n",
      "3598    22   1   1   1\n",
      "3599    23   1   1   1\n"
     ]
    }
   ],
   "source": [
    "num_rows = len(y_pred_logreg_tune)\n",
    "hours = list(range(24)) * (num_rows // 24) + list(range(num_rows % 24))  # Create repeating hours (0-23)\n",
    "# Add the 'Hour' column to y_pred_logreg_tune, y_pred_svm_tune, and y_test_reversed\n",
    "y_pred_logreg_tune['Hour'] = hours[:num_rows]\n",
    "y_pred_svm_tune['Hour'] = hours[:num_rows]\n",
    "y_test_reversed['Hour'] = hours[:num_rows]\n",
    "\n",
    "\n",
    "# Ensure 'Hour' is the first column\n",
    "y_pred_logreg_tune = y_pred_logreg_tune[['Hour', 'G1', 'G2', 'G3']]\n",
    "y_pred_svm_tune = y_pred_svm_tune[['Hour', 'G1', 'G2', 'G3']]\n",
    "y_test_reversed = y_test_reversed[['Hour', 'G1', 'G2', 'G3']]\n",
    "\n",
    "# Save Results to CSV\n",
    "y_pred_logreg_tune.to_csv('y_pred_logreg_tune.csv', index=False)\n",
    "y_pred_svm_tune.to_csv('y_pred_svm_tune.csv', index=False)\n",
    "y_test_reversed.to_csv('y_test.csv', index=False)\n",
    "\n",
    "# Print results\n",
    "print(\"Predicted Values (Tuned Logistic Regression):\")\n",
    "print(y_pred_logreg_tune.head())\n",
    "print(\"Predicted Values (Tuned SVM):\")\n",
    "print(y_pred_svm_tune.head())\n",
    "print(\"\\nTrue Values:\")\n",
    "print(y_test_reversed.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:46:40.766531Z",
     "start_time": "2024-11-22T21:39:50.315229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Unit: G2 ---\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konst\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 0.01, 'solver': 'lbfgs'}\n",
      "Best cross-validated MCC: 0.915\n",
      "--- Logistic Regression Performance for G2 ---\n",
      "Performance Metrics for Tuned Logistic Regression - G2:\n",
      "F1 Score (Weighted): 0.914\n",
      "F1 Score (Macro): 0.899\n",
      "MCC: 0.798\n",
      "Balanced Accuracy: 0.893\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.84      0.86      1125\n",
      "         1.0       0.93      0.95      0.94      2475\n",
      "\n",
      "    accuracy                           0.91      3600\n",
      "   macro avg       0.91      0.89      0.90      3600\n",
      "weighted avg       0.91      0.91      0.91      3600\n",
      "\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m lagged_targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m3\u001b[39m:]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m binary_results \u001b[38;5;241m=\u001b[39m \u001b[43mbinary_classification_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlagged_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlagged_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits_to_classify\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 25\u001b[0m, in \u001b[0;36mbinary_classification_loop\u001b[1;34m(features_lagged, targets, units_to_classify)\u001b[0m\n\u001b[0;32m     22\u001b[0m evaluate_performance(y_test_L, y_pred_logreg, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuned Logistic Regression - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train and Evaluate SVM\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m best_svm_model \u001b[38;5;241m=\u001b[39m \u001b[43mtune_svm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_L\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m y_pred_svm \u001b[38;5;241m=\u001b[39m best_svm_model\u001b[38;5;241m.\u001b[39mpredict(X_test_L)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- SVM Performance for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[31], line 39\u001b[0m, in \u001b[0;36mtune_svm\u001b[1;34m(X_train, y_train)\u001b[0m\n\u001b[0;32m     24\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m],  \u001b[38;5;66;03m# Regularization strength\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# Kernels to evaluate\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegree\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m],  \u001b[38;5;66;03m# Degree of polynomial kernel (ignored for others)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# Kernel coefficient\u001b[39;00m\n\u001b[0;32m     29\u001b[0m }\n\u001b[0;32m     31\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     32\u001b[0m     SVC(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[0;32m     33\u001b[0m     param_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     38\u001b[0m )\n\u001b[1;32m---> 39\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for SVM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest cross-validated MCC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define function for binary classification loop\n",
    "def binary_classification_loop(features_lagged, targets, units_to_classify):\n",
    "    results = {}\n",
    "    for unit in units_to_classify:\n",
    "        print(f\"--- Processing Unit: {unit} ---\")\n",
    "\n",
    "        # Use the specific unit as the target\n",
    "        target = targets[[unit]]\n",
    "\n",
    "        # Train-Test-Validation Split\n",
    "        X_train_L, X_temp_L, y_train_L, y_temp_L = train_test_split(\n",
    "            features_lagged, target, test_size=0.3, random_state=42, shuffle=False\n",
    "        )\n",
    "        X_test_L, X_val_L, y_test_L, y_val_L = train_test_split(\n",
    "            X_temp_L, y_temp_L, test_size=0.5, random_state=42, shuffle=False\n",
    "        )\n",
    "\n",
    "        # Train and Evaluate Logistic Regression\n",
    "        best_logistic_model = tune_log_reg(X_train_L, y_train_L.values.ravel())\n",
    "        y_pred_logreg = best_logistic_model.predict(X_test_L)\n",
    "        print(f\"--- Logistic Regression Performance for {unit} ---\")\n",
    "        evaluate_performance(y_test_L, y_pred_logreg, classes=None, title=f\"Tuned Logistic Regression - {unit}\")\n",
    "\n",
    "        # Train and Evaluate SVM\n",
    "        best_svm_model = tune_svm(X_train_L, y_train_L.values.ravel())\n",
    "        y_pred_svm = best_svm_model.predict(X_test_L)\n",
    "        print(f\"--- SVM Performance for {unit} ---\")\n",
    "        evaluate_performance(y_test_L, y_pred_svm, classes=None, title=f\"Tuned SVM - {unit}\")\n",
    "\n",
    "        # Save Results\n",
    "        results[unit] = {\n",
    "            'logistic': {\n",
    "                'predictions': y_pred_logreg,\n",
    "                'best_model': best_logistic_model,\n",
    "            },\n",
    "            'svm': {\n",
    "                'predictions': y_pred_svm,\n",
    "                'best_model': best_svm_model,\n",
    "            }\n",
    "        }\n",
    "        print(f\"Finished processing unit: {unit}\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Adjust targets\n",
    "lagged_targets = targets.iloc[3:].reset_index(drop=True)  \n",
    "\n",
    "# Call the function\n",
    "binary_results = binary_classification_loop(lagged_features, lagged_targets, units_to_classify)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:46:40.872100Z",
     "start_time": "2024-11-22T21:46:40.773530Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initialize predictions with G1 column (filled with 1s for all rows based on the length of predictions)\n",
    "num_rows = len(next(iter(binary_results.values()))['logistic']['predictions'])  # Get the number of rows from any prediction\n",
    "logistic_predictions = pd.DataFrame({'G1': [1] * num_rows})  # G1 is always 1\n",
    "svm_predictions = pd.DataFrame({'G1': [1] * num_rows})  # G1 is always 1\n",
    "# Add the 'Hour' column to the logistic and SVM predictions\n",
    "\n",
    "# Add G2 and G3 predictions\n",
    "logistic_predictions['G2'] = binary_results['G2']['logistic']['predictions']\n",
    "logistic_predictions['G3'] = binary_results['G3']['logistic']['predictions']\n",
    "\n",
    "svm_predictions['G2'] = binary_results['G2']['svm']['predictions']\n",
    "svm_predictions['G3'] = binary_results['G3']['svm']['predictions']\n",
    "\n",
    "# Add the 'Hour' column to the logistic and SVM predictions\n",
    "logistic_predictions['Hour'] = hours[:num_rows]\n",
    "svm_predictions['Hour'] = hours[:num_rows]\n",
    "\n",
    "# Reorder columns to place 'Hour' first\n",
    "logistic_predictions = logistic_predictions[['Hour', 'G1', 'G2', 'G3']]\n",
    "svm_predictions = svm_predictions[['Hour', 'G1', 'G2', 'G3']]\n",
    "\n",
    "# Save consolidated predictions to CSV\n",
    "logistic_predictions.to_csv('logistic_predictions.csv', index=False)\n",
    "svm_predictions.to_csv('svm_predictions.csv', index=False)\n",
    "# Optional: Save results for each unit\n",
    "#for unit, result in binary_results.items():\n",
    "   # pd.DataFrame(result['logistic']['predictions'], columns=[f\"{unit}_logistic\"]).to_csv(f'Data/{unit}_logistic_predictions.csv', index=False)\n",
    "    #pd.DataFrame(result['svm']['predictions'], columns=[f\"{unit}_svm\"]).to_csv(f'Data/{unit}_svm_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the output of the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert the csv file path that shall be tested in y_pred \n",
    "# import the csv files X_val, y_val and y_pred\n",
    "X_val = pd.read_csv('X_test_MC.csv', delimiter=',')\n",
    "#y_val = pd.read_csv('../Data/y_val.csv', delimiter=',')\n",
    "y_pred = pd.read_csv('y_pred_logreg_tune.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the data folder\n",
    "bus = pd.read_csv('B (power transfer factor of each bus to each line).csv', delimiter=';')\n",
    "max_prod = pd.read_csv('Maximum production of generating units.csv', delimiter=';')\n",
    "min_prod = pd.read_csv('Minimum production of generating units.csv', delimiter=';')\n",
    "min_down_time = pd.read_csv('Minimum down time of generating units.csv', delimiter=';')\n",
    "min_up_time = pd.read_csv('Minimum up time of generating units.csv', delimiter=';')\n",
    "prod_cost = pd.read_csv('Production cost of generating units.csv', delimiter=';')\n",
    "ramp_rate = pd.read_csv('Ramping rate of generating units.csv', delimiter=';')\n",
    "start_up_cost = pd.read_csv('Start-up cost of generating units.csv', delimiter=';')\n",
    "transmission_cap = pd.read_csv('Transmission capacity of lines.csv', delimiter=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nodes = ['Node 1', 'Node 2', 'Node 3', 'Node 4', 'Node 5', 'Node 6']\n",
    "Generator = ['G1', 'G2', 'G3']\n",
    "Generator_node = {'Node 1': 'G1', 'Node 2': 'G2', 'Node 6': 'G3'}\n",
    "Load = ['L1', 'L2', 'L3']\n",
    "Load_node = {'Node 4': 'L1', 'Node 5': 'L2', 'Node 6': 'L3'}\n",
    "Wind = ['W1', 'W2']\n",
    "Wind_node = {'Node 4': 'W1', 'Node 5': 'W2'}\n",
    "Transmission = ['Line 1', 'Line 2', 'Line 3', 'Line 4', 'Line 5', 'Line 6','Line 7']\n",
    "Transmission_node = {'Line 1': ['Node 1', 'Node 2'], 'Line 2': ['Node 2', 'Node 3'], 'Line 3': ['Node 3', 'Node 6'], 'Line 4': ['Node 5', 'Node 6'], 'Line 5': ['Node 4', 'Node 5'], 'Line 6': ['Node 2', 'Node 4'],'Line 6': ['Node 1', 'Node 4']}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix with the nodes as columns and the generators, loads and winds as rows, with 1 if connected to the node\n",
    "Gen_n = np.zeros((len(Generator), len(Nodes)))\n",
    "Load_n = np.zeros((len(Load), len(Nodes)))\n",
    "Wind_n = np.zeros((len(Wind), len(Nodes)))\n",
    "Transmission_n = np.zeros((len(Transmission), len(Nodes)))\n",
    "\n",
    "# Populate the matrix\n",
    "for i, g in enumerate(Generator):  # Iterate over generators\n",
    "    for j, node in enumerate(Nodes):  # Iterate over nodes\n",
    "        if Generator_node.get(node) == g:  # Check if generator is connected to the node\n",
    "            Gen_n[i, j] = 1\n",
    "\n",
    "for i, l in enumerate(Load):  # Iterate over loads\n",
    "    for j, node in enumerate(Nodes):  # Iterate over nodes\n",
    "        if Load_node.get(node) == l:  # Check if load is connected to the node\n",
    "            Load_n[i, j] = 1\n",
    "\n",
    "for i, w in enumerate(Wind):  # Iterate over winds\n",
    "    for j, node in enumerate(Nodes):  # Iterate over nodes\n",
    "        if Wind_node.get(node) == w:  # Check if wind is connected to the node\n",
    "            Wind_n[i, j] = 1\n",
    "\n",
    "for i, t in enumerate(Transmission):  # Iterate over transmission lines\n",
    "    connected_nodes = Transmission_node.get(t, [])  # Get nodes connected by the transmission line\n",
    "    for node in connected_nodes:  # For each node connected by the transmission line\n",
    "        if node in Nodes:  # Ensure the node is valid (exists in Nodes list)\n",
    "            j = Nodes.index(node)  # Get the column index for the node in Transmission_n\n",
    "            Transmission_n[i, j] = 1  # Set the corresponding element to 1\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input data class\n",
    "class InputData:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        wind_forecast: pd.DataFrame, \n",
    "        bus: pd.DataFrame,\n",
    "        load: pd.DataFrame,\n",
    "        max_prod: pd.DataFrame,\n",
    "        min_prod: pd.DataFrame,\n",
    "        min_down_time: pd.DataFrame,\n",
    "        min_up_time: pd.DataFrame,\n",
    "        prod_cost: pd.DataFrame,\n",
    "        ramp_rate: pd.DataFrame,\n",
    "        start_up_cost: pd.DataFrame,\n",
    "        transmission_cap: pd.DataFrame\n",
    "    ):\n",
    "        self.time = range(len(wind_forecast))  #maybe define it with lenght of wind_production\n",
    "        self.wind_forecast = wind_forecast\n",
    "        self.bus = bus\n",
    "        self.load = load\n",
    "        self.max_prod = max_prod\n",
    "        self.min_prod = min_prod\n",
    "        self.min_down_time = min_down_time\n",
    "        self.min_up_time = min_up_time\n",
    "        self.prod_cost = prod_cost\n",
    "        self.ramp_rate = ramp_rate\n",
    "        self.start_up_cost = start_up_cost\n",
    "        self.transmission_cap = transmission_cap\n",
    "        self.M = 1000000  # Penalty for having flexible demand\n",
    "        self.Gen_n = Gen_n  # Matrix mapping generators to nodes\n",
    "        self.Load_n = Load_n # Matrix mapping loads to nodes\n",
    "        self.Wind_n = Wind_n # Matrix mapping wind to nodes\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expando(object):\n",
    "    '''\n",
    "        A small class which can have attributes set\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimization model class\n",
    "\n",
    "class EconomicDispatch_Test():\n",
    "        \n",
    "        def __init__(self, input_data: InputData, y_pred: pd.DataFrame):\n",
    "            self.data = input_data \n",
    "            self.y_pred = y_pred.T\n",
    "            self.variables = Expando()\n",
    "            self.constraints = Expando() \n",
    "            self.results = Expando() \n",
    "            self._build_model() \n",
    "            \n",
    "        def _build_variables(self):\n",
    "            # one variable for each generator for each time of the day\n",
    "            self.variables.prod_gen = {\n",
    "                 (i, t): self.model.addVar(lb=0, ub=self.data.max_prod.iloc[i-1, 0], \n",
    "                                           name='generation_G{}_{}'.format(i, t)) \n",
    "                                           for i in range(1, len(self.data.max_prod)+1) \n",
    "                                           for t in self.data.time}\n",
    "            \n",
    "            # one variable for each wind generator for each time of the day\n",
    "            self.variables.prod_wind = {\n",
    "                 (i, t): self.model.addVar(lb=0, ub=self.data.wind_forecast.iloc[t, i], \n",
    "                                            name='wind_generation_W{}_{}'.format(i, t)) \n",
    "                                            for i in range(1, len(self.data.wind_forecast.iloc[0, :])) \n",
    "                                            for t in self.data.time}\n",
    "            \n",
    "            # one variable for each start-up cost for each generator\n",
    "            self.variables.start_up_cost = {\n",
    "                 (i, t): self.model.addVar(lb=0, \n",
    "                                            name='start_up_cost_G{}_{}'.format(i, t)) \n",
    "                                            for i in range(1, len(self.data.max_prod)+1) \n",
    "                                            for t in self.data.time}\n",
    "            \n",
    "            # add two slack variables to always make the model feasible, allowing the demand to be flexible\n",
    "            self.variables.epsilon = {\n",
    "                 (n, t): self.model.addVar(lb=0, \n",
    "                                           name='epsilon_Bus{}_{}'.format(n, t)) \n",
    "                                           for n in range(1, len(self.data.bus.iloc[0,:])+1) \n",
    "                                           for t in self.data.time}\n",
    "            self.variables.delta = {\n",
    "                 (n, t): self.model.addVar(lb=0, \n",
    "                                           name='delta_Bus{}_{}'.format(n, t))\n",
    "                                           for n in range(1, len(self.data.bus.iloc[0,:])+1)\n",
    "                                           for t in self.data.time}\n",
    "            \n",
    "            # add two slack variables to always make the model feasible, relaxing the min_up_time and min_down_time constraints\n",
    "            self.variables.alpha = {\n",
    "                    (i, t, to): self.model.addVar(lb=0,\n",
    "                                            name='alpha_G{}_{}_{}'.format(i, t, to))\n",
    "                                            for i in range(1, len(self.data.max_prod)+1)\n",
    "                                            for t in self.data.time\n",
    "                                            for to in range(t, min(t + self.data.min_up_time.iloc[i-1, 0], len(self.data.time))) if t > 0}\n",
    "            self.variables.beta = {\n",
    "                    (i, t, to): self.model.addVar(lb=0,\n",
    "                                            name='beta_G{}_{}_{}'.format(i, t, to))\n",
    "                                            for i in range(1, len(self.data.max_prod)+1)\n",
    "                                            for t in self.data.time\n",
    "                                            for to in range(t, min(t + self.data.min_down_time.iloc[i-1, 0], len(self.data.time))) if t > 0}\n",
    "\n",
    "            \n",
    "            \n",
    "        def _build_constraints(self):\n",
    "            # Minimum capacity of the generator\n",
    "            self.constraints.min_capacity = {\n",
    "                (i, t): self.model.addConstr(\n",
    "                    self.variables.prod_gen[i, t] >= self.data.min_prod.iloc[i-1, 0] * self.y_pred.iloc[i, t]\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) for t in self.data.time}\n",
    "            # Maximum capacity of the generator\n",
    "            self.constraints.max_capacity = {\n",
    "                (i, t): self.model.addConstr(\n",
    "                    self.variables.prod_gen[i, t] <= self.data.max_prod.iloc[i-1, 0] * self.y_pred.iloc[i, t]\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) for t in self.data.time}\n",
    "\n",
    "            # Power balance constraint\n",
    "            self.constraints.power_balance = {\n",
    "                t: self.model.addConstr(\n",
    "                    gp.quicksum(self.variables.prod_gen[i, t] for i in range(1, len(self.data.max_prod) + 1)) +\n",
    "                    gp.quicksum(self.variables.prod_wind[i, t] for i in range(1, len(self.data.wind_forecast.iloc[0, :]))) == \n",
    "                    gp.quicksum(self.data.load.iloc[t, i] * Load_n[i-1, n-1] for i in range(1, len(self.data.load.iloc[0, :]))for n in range(1, len(self.data.bus.iloc[0, :]) + 1))\n",
    "                    + gp.quicksum(self.variables.epsilon[n, t] - self.variables.delta[n, t] for n in range(1, len(self.data.bus.iloc[0, :]) + 1))\n",
    "                ) for t in self.data.time}\n",
    "        \n",
    "            # Transmission capacity constraint up\n",
    "            self.constraints.transmission_capacity_up = {\n",
    "                    (l, t): self.model.addConstr(\n",
    "                        gp.quicksum(\n",
    "                            self.data.bus.iloc[l-1, n-1] * Transmission_n[l-1, n-1] * (\n",
    "                                self.variables.prod_gen[g, t] * Gen_n[g-1, n-1] +\n",
    "                                self.variables.prod_wind[w, t] * Wind_n[w-1, n-1] -\n",
    "                                self.data.load.iloc[t, i] * Load_n[i-1, n-1] -\n",
    "                                self.variables.epsilon[n, t] +\n",
    "                                self.variables.delta[n, t]\n",
    "                            )\n",
    "                            for n in range(1, len(self.data.bus.iloc[0, :]) + 1)\n",
    "                            for i in range(1, len(self.data.load.iloc[0, :]))\n",
    "                            for g in range(1, len(self.data.max_prod) + 1)\n",
    "                            for w in range(1, len(self.data.wind_forecast.iloc[0, :]))\n",
    "                        ) <= self.data.transmission_cap.iloc[l-1, 0],\n",
    "                        name=\"transmission_capacity_up_L{}_T{}\".format(l, t)\n",
    "                    ) for l in range(1, len(self.data.transmission_cap) + 1)\n",
    "                    for t in self.data.time\n",
    "                }\n",
    "\n",
    "            #Transmission capacity constraint down\n",
    "            self.constraints.transmission_capacity_down = {\n",
    "                    (l, t): self.model.addConstr(\n",
    "                        gp.quicksum(\n",
    "                            self.data.bus.iloc[l-1, n-1] * Transmission_n[l-1, n-1] * (\n",
    "                                self.variables.prod_gen[g, t] * Gen_n[g-1, n-1] +\n",
    "                                self.variables.prod_wind[w, t] * Wind_n[w-1, n-1] -\n",
    "                                self.data.load.iloc[t, i] * Load_n[i-1, n-1] -\n",
    "                                self.variables.epsilon[n, t] +\n",
    "                                self.variables.delta[n, t]\n",
    "                            )\n",
    "                            for n in range(1, len(self.data.bus.iloc[0, :]) + 1)\n",
    "                            for i in range(1, len(self.data.load.iloc[0, :]))\n",
    "                            for g in range(1, len(self.data.max_prod) + 1)\n",
    "                            for w in range(1, len(self.data.wind_forecast.iloc[0, :]))\n",
    "                        ) >= -self.data.transmission_cap.iloc[l-1, 0],\n",
    "                        name=\"transmission_capacity_down_L{}_T{}\".format(l, t)\n",
    "                    ) for l in range(1, len(self.data.transmission_cap) + 1)\n",
    "                    for t in self.data.time\n",
    "                }\n",
    "\n",
    "            #Start-up costs constraint\n",
    "            self.constraints.start_up_cost = {\n",
    "                (i, t): self.model.addConstr(\n",
    "                    self.variables.start_up_cost[i, t] >= self.data.start_up_cost.iloc[i-1, 0] * (self.y_pred.iloc[i, t] - self.y_pred.iloc[i, t-1])\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) for t in self.data.time if t > 0}\n",
    "            self.constraints.start_up_cost_0 = {\n",
    "                i: self.model.addConstr(\n",
    "                    self.variables.start_up_cost[i, 0] >= self.data.start_up_cost.iloc[i-1, 0] * self.y_pred.iloc[i, 0]\n",
    "                ) for i in range(1, len(self.data.max_prod)+1)}\n",
    "            \n",
    "            # Ramping constraint\n",
    "            self.constraints.ramping_up = {\n",
    "                (i, t): self.model.addConstr(\n",
    "                    self.variables.prod_gen[i, t] - self.variables.prod_gen[i, t-1] <= self.data.ramp_rate.iloc[i-1, 0]\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) for t in self.data.time if t > 0}\n",
    "            self.constraints.ramping_down = {\n",
    "                (i, t): self.model.addConstr(\n",
    "                    self.variables.prod_gen[i, t-1] - self.variables.prod_gen[i, t] <= self.data.ramp_rate.iloc[i-1, 0]\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) for t in self.data.time if t > 0}\n",
    "            \n",
    "            # Minimum up time constraint\n",
    "            self.constraints.min_up_time = {\n",
    "                (i, t, to): self.model.addConstr(\n",
    "                    -self.y_pred.iloc[i, t - 1] + self.y_pred.iloc[i, t] - self.y_pred.iloc[i, to] - self.variables.alpha[i, t, to] <= 0\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) \n",
    "                for t in self.data.time \n",
    "                for to in range(t, min(t + self.data.min_up_time.iloc[i-1, 0], len(self.data.time))) if t > 0}\n",
    "            \n",
    "            # Minimum down time constraint\n",
    "            self.constraints.min_down_time = {\n",
    "                (i, t, to): self.model.addConstr(\n",
    "                    self.y_pred.iloc[i, t - 1] - self.y_pred.iloc[i, t] + self.y_pred.iloc[i, to] - self.variables.beta[i, t, to] <= 1\n",
    "                ) for i in range(1, len(self.data.max_prod)+1) \n",
    "                for t in self.data.time \n",
    "                for to in range(t, min(t + self.data.min_down_time.iloc[i-1, 0], len(self.data.time))) if t > 0}\n",
    "            \n",
    "\n",
    "\n",
    "        def _build_objective(self):\n",
    "            # Objective function\n",
    "            self.model.setObjective(\n",
    "                gp.quicksum(self.data.prod_cost.iloc[i-1, 0]*self.variables.prod_gen[i, t] for i in range(1, len(self.data.max_prod)+1) for t in self.data.time) +\n",
    "                gp.quicksum(self.variables.start_up_cost[i, t] for i in range(1, len(self.data.max_prod)+1) for t in self.data.time) +\n",
    "                self.data.M * (gp.quicksum(self.variables.epsilon[n, t] + self.variables.delta[n, t] for n in range(1, len(self.data.bus.iloc[0,:])+1) for t in self.data.time)) +\n",
    "                self.data.M * (gp.quicksum(self.variables.alpha[i, t, to] for i in range(1, len(self.data.max_prod)+1) for t in self.data.time for to in range(t, min(t + self.data.min_up_time.iloc[i-1, 0], len(self.data.time))) if t > 0)) +\n",
    "                self.data.M * (gp.quicksum(self.variables.beta[i, t, to] for i in range(1, len(self.data.max_prod)+1) for t in self.data.time for to in range(t, min(t + self.data.min_down_time.iloc[i-1, 0], len(self.data.time))) if t > 0))\n",
    "            )\n",
    "\n",
    "        def _build_model(self):\n",
    "            self.model = gp.Model('EconomicDispatch')\n",
    "            self._build_variables()\n",
    "            self._build_constraints()\n",
    "            self._build_objective()\n",
    "            self.model.update()\n",
    "\n",
    "        def optimize(self):\n",
    "            self.model.optimize()\n",
    "            self._extract_results()\n",
    "\n",
    "        def _extract_results(self):\n",
    "            self.results.production = pd.DataFrame({\n",
    "                \n",
    "                'hour': [self.data.wind_forecast.iloc[t, 0] for t in self.data.time],\n",
    "                #'time': [t for t in self.data.time],\n",
    "                #'status G1': [self.y_pred.iloc[1, t] for t in self.data.time],\n",
    "                #'status G2': [self.y_pred.iloc[2, t] for t in self.data.time],\n",
    "                #'status G3': [self.y_pred.iloc[3, t] for t in self.data.time],\n",
    "                #'start_up_cost 1': [self.variables.start_up_cost[1, t].x for t in self.data.time],\n",
    "                #'start_up_cost 2': [self.variables.start_up_cost[2, t].x for t in self.data.time],\n",
    "                #'start_up_cost 3': [self.variables.start_up_cost[3, t].x for t in self.data.time],\n",
    "                #'generation 1': [self.variables.prod_gen[1, t].x for t in self.data.time],\n",
    "                #'generation 2': [self.variables.prod_gen[2, t].x for t in self.data.time],\n",
    "                #'generation 3': [self.variables.prod_gen[3, t].x for t in self.data.time],\n",
    "                #'wind generation 1': [self.variables.prod_wind[1, t].x for t in self.data.time],\n",
    "                #'wind generation 2': [self.variables.prod_wind[2, t].x for t in self.data.time],\n",
    "                #'load 1': [self.data.load.iloc[t, 1] for t in self.data.time],\n",
    "                #'load 2': [self.data.load.iloc[t, 2] for t in self.data.time],\n",
    "                #'load 3': [self.data.load.iloc[t, 3] for t in self.data.time],\n",
    "                #'epsilon 1': [self.variables.epsilon[1, t].x for t in self.data.time],\n",
    "                #'delta 1': [self.variables.delta[1, t].x for t in self.data.time],\n",
    "                #'epsilon 2': [self.variables.epsilon[2, t].x for t in self.data.time],\n",
    "                #'delta 2': [self.variables.delta[2, t].x for t in self.data.time],\n",
    "                #'epsilon 3': [self.variables.epsilon[3, t].x for t in self.data.time],\n",
    "                #'delta 3': [self.variables.delta[3, t].x for t in self.data.time],\n",
    "                #'epsilon 4': [self.variables.epsilon[4, t].x for t in self.data.time],\n",
    "                #'delta 4': [self.variables.delta[4, t].x for t in self.data.time],\n",
    "                #'epsilon 5': [self.variables.epsilon[5, t].x for t in self.data.time],\n",
    "                #'delta 5': [self.variables.delta[5, t].x for t in self.data.time],\n",
    "                #'epsilon 6': [self.variables.epsilon[6, t].x for t in self.data.time],\n",
    "                #'delta 6': [self.variables.delta[6, t].x for t in self.data.time]\n",
    "            })\n",
    "\n",
    "            # Add columns for each transmission line's binding status at each time\n",
    "            for l in range(1, len(self.data.transmission_cap) + 1):\n",
    "                up_binding = []\n",
    "                down_binding = []\n",
    "                \n",
    "                for t in self.data.time:\n",
    "                    up_constraint = self.constraints.transmission_capacity_up[l, t]\n",
    "                    down_constraint = self.constraints.transmission_capacity_down[l, t]\n",
    "\n",
    "                    # Append binding status (True if binding, based on slack value)\n",
    "                    up_binding.append(abs(up_constraint.slack) < 1e-6)\n",
    "                    down_binding.append(abs(down_constraint.slack) < 1e-6)\n",
    "\n",
    "                # Add the binding status as new columns in the main production DataFrame\n",
    "                self.results.production[f'transmission_up_binding_L{l}'] = up_binding\n",
    "                self.results.production[f'transmission_down_binding_L{l}'] = down_binding\n",
    "\n",
    "            # Add the alpha and beta variables to the results\n",
    "            self.results.alpha1 = [gp.quicksum(self.variables.alpha[1, t, to].x  for to in range(t, min(t + self.data.min_up_time.iloc[0, 0], len(self.data.time))) if t > 0) for t in self.data.time]\n",
    "            self.results.alpha2 = [gp.quicksum(self.variables.alpha[2, t, to].x  for to in range(t, min(t + self.data.min_up_time.iloc[1, 0], len(self.data.time))) if t > 0) for t in self.data.time]\n",
    "            self.results.alpha3 = [gp.quicksum(self.variables.alpha[3, t, to].x  for to in range(t, min(t + self.data.min_up_time.iloc[2, 0], len(self.data.time))) if t > 0) for t in self.data.time]\n",
    "            self.results.beta1 = [gp.quicksum(self.variables.beta[1, t, to].x  for to in range(t, min(t + self.data.min_down_time.iloc[0, 0], len(self.data.time))) if t > 0) for t in self.data.time]\n",
    "            self.results.beta2 = [gp.quicksum(self.variables.beta[2, t, to].x  for to in range(t, min(t + self.data.min_down_time.iloc[1, 0], len(self.data.time))) if t > 0) for t in self.data.time]\n",
    "            self.results.beta3 = [gp.quicksum(self.variables.beta[3, t, to].x  for to in range(t, min(t + self.data.min_down_time.iloc[2, 0], len(self.data.time))) if t > 0) for t in self.data.time]\n",
    "            \n",
    "\n",
    "                                  \n",
    "            self.results.objective = self.model.objVal\n",
    "            \n",
    "        def _print_model(self):\n",
    "            self.model.write('EconomicDispatch.lp')        \n",
    "            \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-01-29\n",
      "Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: AMD Ryzen 5 5500U with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 161963 rows, 125969 columns and 392357 nonzeros\n",
      "Model fingerprint: 0x11882576\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-01, 1e+01]\n",
      "  Objective range  [1e+00, 1e+06]\n",
      "  Bounds range     [5e-03, 2e+02]\n",
      "  RHS range        [5e-02, 9e+02]\n",
      "Presolve removed 127456 rows and 69085 columns\n",
      "Presolve time: 0.25s\n",
      "Presolved: 34507 rows, 87374 columns, 198156 nonzeros\n",
      "\n",
      "Concurrent LP optimizer: primal simplex, dual simplex, and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Ordering time: 0.04s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 9.014e+04\n",
      " Factor NZ  : 3.399e+05 (roughly 50 MB of memory)\n",
      " Factor Ops : 3.833e+06 (less than 1 second per iteration)\n",
      " Threads    : 4\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   3.88043033e+12 -9.63223247e+11  5.59e+02 1.03e-01  6.18e+07     0s\n",
      "   1   5.11943189e+11 -4.47418969e+11  5.96e+01 2.33e-10  8.80e+06     1s\n",
      "   2   1.32121701e+11 -7.65765922e+10  1.28e+01 3.49e-10  1.72e+06     1s\n",
      "\n",
      "Barrier performed 2 iterations in 0.59 seconds (0.20 work units)\n",
      "Barrier solve interrupted - model solved by another algorithm\n",
      "\n",
      "\n",
      "Solved with dual simplex\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   10049    1.8825960e+10   0.000000e+00   0.000000e+00      1s\n",
      "\n",
      "Solved in 10049 iterations and 0.71 seconds (0.22 work units)\n",
      "Optimal objective  1.882595998e+10\n"
     ]
    }
   ],
   "source": [
    "# Run the model test\n",
    "wind_forecast_test = X_val.drop(columns=['L1', 'L2', 'L3'])\n",
    "load_test = X_val.drop(columns=['W1', 'W2'])\n",
    "input_data = InputData(wind_forecast_test, bus, load_test, max_prod, min_prod, min_down_time, min_up_time, prod_cost, ramp_rate, start_up_cost, transmission_cap)\n",
    "model_test = EconomicDispatch_Test(input_data, y_pred)\n",
    "#model_test = EconomicDispatch_Test(input_data, y_pred.head(24))\n",
    "model_test.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the sum of the alpha and beta variables\n",
    "unfeasible_hours_y_test = []\n",
    "for i in range (1, 4):\n",
    "    alpha = [\n",
    "        sum(\n",
    "            model_test.variables.alpha[i, t, to].x\n",
    "            for to in range(t, min(t + model_test.data.min_up_time.iloc[i-1, 0], len(model_test.data.time)))\n",
    "        if t > 0\n",
    "        )\n",
    "        for t in model_test.data.time\n",
    "    ]\n",
    "    unfeasible_hours_y_test.append(sum(alpha))\n",
    "    beta = [\n",
    "        sum(\n",
    "            model_test.variables.beta[i, t, to].x\n",
    "            for to in range(t, min(t + model_test.data.min_down_time.iloc[i-1, 0], len(model_test.data.time)))\n",
    "        if t > 0\n",
    "        )\n",
    "        for t in model_test.data.time\n",
    "    ]\n",
    "    unfeasible_hours_y_test.append(sum(alpha))\n",
    "\n",
    "# Print the number of unfeasible hours for each generator\n",
    "print('Total number of hours:', len(model_test.data.time))\n",
    "print('Unfeasible hours for generator 1:', unfeasible_hours_y_test[0]+ unfeasible_hours_y_test[1], ', so', round((unfeasible_hours_y_test[0]+ unfeasible_hours_y_test[1])/len(model_test.data.time)*100, 2), '% of the total hours')\n",
    "print('Unfeasible hours for generator 2:', unfeasible_hours_y_test[2]+ unfeasible_hours_y_test[3], ', so', round((unfeasible_hours_y_test[2]+ unfeasible_hours_y_test[3])/len(model_test.data.time)*100, 2), '% of the total hours')\n",
    "print('Unfeasible hours for generator 3:', unfeasible_hours_y_test[4]+ unfeasible_hours_y_test[5], ', so', round((unfeasible_hours_y_test[4]+ unfeasible_hours_y_test[5])/len(model_test.data.time)*100, 2), '% of the total hours')\n",
    "\n",
    "# Save the list unfeasible_hours_svm_pred to a csv file\n",
    "unfeasible_hours_y_test = pd.DataFrame(unfeasible_hours_y_test)\n",
    "unfeasible_hours_y_test.to_csv('unfeasible_hours_y_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
